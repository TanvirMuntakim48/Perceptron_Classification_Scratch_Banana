{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing Perceptron Algorithm from Scratch\n",
        "\n",
        "In this notebook, I implement Logistic Regression using Perceptron unit from scratch and I further add a few extra things like:\n",
        "* Mini-Batch Training\n",
        "* L2 Regularization\n",
        "\n",
        "The logistic regression model is trained on the Banana dataset obtained from kaggle: https://www.kaggle.com/datasets/l3llff/banana\n",
        "\n",
        "This code is almost the same as the Logistic Regression Implementation on Banana Quality Dataset, only difference is the use of Perceptron activation instead of the Sigmoid activation"
      ],
      "metadata": {
        "id": "nT9Ayph70-we"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1lo6nnri_Su"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "%matplotlib inline\n",
        "\n",
        "from scipy.io import loadmat\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "yHaqWDXEjTdo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a88a3a1e-5834-45af-def5-d4c1af883145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('banana_quality.csv')\n",
        "\n",
        "print(data.shape)"
      ],
      "metadata": {
        "id": "uSPMDjFKkxvQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a858206e-3851-4064-ca76-b8e211c6b088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8000, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Uj5hHFeWk2QY",
        "outputId": "f8a0b252-2c7f-4e49-ebe7-4e6d44bdee73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Size    Weight  Sweetness  Softness  HarvestTime  Ripeness   Acidity  \\\n",
              "0 -1.924968  0.468078   3.077832 -1.472177     0.294799  2.435570  0.271290   \n",
              "1 -2.409751  0.486870   0.346921 -2.495099    -0.892213  2.067549  0.307325   \n",
              "2 -0.357607  1.483176   1.568452 -2.645145    -0.647267  3.090643  1.427322   \n",
              "3 -0.868524  1.566201   1.889605 -1.273761    -1.006278  1.873001  0.477862   \n",
              "4  0.651825  1.319199  -0.022459 -1.209709    -1.430692  1.078345  2.812442   \n",
              "\n",
              "  Quality  \n",
              "0    Good  \n",
              "1    Good  \n",
              "2    Good  \n",
              "3    Good  \n",
              "4    Good  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0762a42e-c3ab-4224-b8fe-1e55c301a117\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Size</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Sweetness</th>\n",
              "      <th>Softness</th>\n",
              "      <th>HarvestTime</th>\n",
              "      <th>Ripeness</th>\n",
              "      <th>Acidity</th>\n",
              "      <th>Quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.924968</td>\n",
              "      <td>0.468078</td>\n",
              "      <td>3.077832</td>\n",
              "      <td>-1.472177</td>\n",
              "      <td>0.294799</td>\n",
              "      <td>2.435570</td>\n",
              "      <td>0.271290</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-2.409751</td>\n",
              "      <td>0.486870</td>\n",
              "      <td>0.346921</td>\n",
              "      <td>-2.495099</td>\n",
              "      <td>-0.892213</td>\n",
              "      <td>2.067549</td>\n",
              "      <td>0.307325</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.357607</td>\n",
              "      <td>1.483176</td>\n",
              "      <td>1.568452</td>\n",
              "      <td>-2.645145</td>\n",
              "      <td>-0.647267</td>\n",
              "      <td>3.090643</td>\n",
              "      <td>1.427322</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.868524</td>\n",
              "      <td>1.566201</td>\n",
              "      <td>1.889605</td>\n",
              "      <td>-1.273761</td>\n",
              "      <td>-1.006278</td>\n",
              "      <td>1.873001</td>\n",
              "      <td>0.477862</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.651825</td>\n",
              "      <td>1.319199</td>\n",
              "      <td>-0.022459</td>\n",
              "      <td>-1.209709</td>\n",
              "      <td>-1.430692</td>\n",
              "      <td>1.078345</td>\n",
              "      <td>2.812442</td>\n",
              "      <td>Good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0762a42e-c3ab-4224-b8fe-1e55c301a117')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0762a42e-c3ab-4224-b8fe-1e55c301a117 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0762a42e-c3ab-4224-b8fe-1e55c301a117');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-86ef0afd-3432-4f59-a300-48f313976b98\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86ef0afd-3432-4f59-a300-48f313976b98')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-86ef0afd-3432-4f59-a300-48f313976b98 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 8000,\n  \"fields\": [\n    {\n      \"column\": \"Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1360227918920454,\n        \"min\": -7.9980736,\n        \"max\": 7.9708004,\n        \"num_unique_values\": 8000,\n        \"samples\": [\n          -1.1823753,\n          -2.1902218,\n          -0.01742254\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.015934252771929,\n        \"min\": -8.283002,\n        \"max\": 5.679692,\n        \"num_unique_values\": 8000,\n        \"samples\": [\n          -1.5233536,\n          -2.8090863,\n          1.1875557\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sweetness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9484548834162483,\n        \"min\": -6.4340215,\n        \"max\": 7.539374,\n        \"num_unique_values\": 8000,\n        \"samples\": [\n          -1.3909012,\n          -1.3944167,\n          4.7572994\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Softness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.065215944309168,\n        \"min\": -6.9593196,\n        \"max\": 8.241555,\n        \"num_unique_values\": 8000,\n        \"samples\": [\n          -0.850838,\n          2.6063178,\n          1.0700845\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HarvestTime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9966607874097069,\n        \"min\": -7.5700083,\n        \"max\": 6.29328,\n        \"num_unique_values\": 8000,\n        \"samples\": [\n          -0.13659394,\n          -0.016427217,\n          -2.5047512\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ripeness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.1142893721428417,\n        \"min\": -7.4231553,\n        \"max\": 7.2490335,\n        \"num_unique_values\": 8000,\n        \"samples\": [\n          2.3312151,\n          5.5374675,\n          -1.0434868\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Acidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.2934666385409743,\n        \"min\": -8.226977,\n        \"max\": 7.4116335,\n        \"num_unique_values\": 8000,\n        \"samples\": [\n          -1.8286724,\n          -4.9408426,\n          2.5416763\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Quality\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Bad\",\n          \"Good\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "KpLGS8RtlX4L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae57a29c-4055-42e3-bcf2-46c8b2f224d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 8000 entries, 0 to 7999\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   Size         8000 non-null   float64\n",
            " 1   Weight       8000 non-null   float64\n",
            " 2   Sweetness    8000 non-null   float64\n",
            " 3   Softness     8000 non-null   float64\n",
            " 4   HarvestTime  8000 non-null   float64\n",
            " 5   Ripeness     8000 non-null   float64\n",
            " 6   Acidity      8000 non-null   float64\n",
            " 7   Quality      8000 non-null   object \n",
            "dtypes: float64(7), object(1)\n",
            "memory usage: 500.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvPfcMoucPc-",
        "outputId": "56bc96a5-ccad-4f61-ce58-b82ad497a28a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-klIM4EcTC_",
        "outputId": "ec17742c-23e8-4468-d13c-fbb9111b86f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Size          -2.807722\n",
              "Weight         1.138136\n",
              "Sweetness      3.447627\n",
              "Softness      -1.713302\n",
              "HarvestTime   -2.220912\n",
              "Ripeness        2.07941\n",
              "Acidity        2.281203\n",
              "Quality            Good\n",
              "Name: 5, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Sweetness'].max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqCoJncecfIV",
        "outputId": "f67a205b-1011-45c8-bd07-880ef9fedae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.539374"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "rkNhUE-qc060",
        "outputId": "9e98fe36-7f3c-4628-bc9c-1eef5cd4dea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Size       Weight    Sweetness     Softness  HarvestTime  \\\n",
              "count  8000.000000  8000.000000  8000.000000  8000.000000  8000.000000   \n",
              "mean     -0.747802    -0.761019    -0.770224    -0.014441    -0.751288   \n",
              "std       2.136023     2.015934     1.948455     2.065216     1.996661   \n",
              "min      -7.998074    -8.283002    -6.434022    -6.959320    -7.570008   \n",
              "25%      -2.277651    -2.223574    -2.107329    -1.590458    -2.120659   \n",
              "50%      -0.897514    -0.868659    -1.020673     0.202644    -0.934192   \n",
              "75%       0.654216     0.775491     0.311048     1.547120     0.507326   \n",
              "max       7.970800     5.679692     7.539374     8.241555     6.293280   \n",
              "\n",
              "          Ripeness      Acidity  \n",
              "count  8000.000000  8000.000000  \n",
              "mean      0.781098     0.008725  \n",
              "std       2.114289     2.293467  \n",
              "min      -7.423155    -8.226977  \n",
              "25%      -0.574226    -1.629450  \n",
              "50%       0.964952     0.098735  \n",
              "75%       2.261650     1.682063  \n",
              "max       7.249034     7.411633  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2db502fd-284d-4ea5-b6b1-6ffad46f9d4e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Size</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Sweetness</th>\n",
              "      <th>Softness</th>\n",
              "      <th>HarvestTime</th>\n",
              "      <th>Ripeness</th>\n",
              "      <th>Acidity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>8000.000000</td>\n",
              "      <td>8000.000000</td>\n",
              "      <td>8000.000000</td>\n",
              "      <td>8000.000000</td>\n",
              "      <td>8000.000000</td>\n",
              "      <td>8000.000000</td>\n",
              "      <td>8000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-0.747802</td>\n",
              "      <td>-0.761019</td>\n",
              "      <td>-0.770224</td>\n",
              "      <td>-0.014441</td>\n",
              "      <td>-0.751288</td>\n",
              "      <td>0.781098</td>\n",
              "      <td>0.008725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.136023</td>\n",
              "      <td>2.015934</td>\n",
              "      <td>1.948455</td>\n",
              "      <td>2.065216</td>\n",
              "      <td>1.996661</td>\n",
              "      <td>2.114289</td>\n",
              "      <td>2.293467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-7.998074</td>\n",
              "      <td>-8.283002</td>\n",
              "      <td>-6.434022</td>\n",
              "      <td>-6.959320</td>\n",
              "      <td>-7.570008</td>\n",
              "      <td>-7.423155</td>\n",
              "      <td>-8.226977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-2.277651</td>\n",
              "      <td>-2.223574</td>\n",
              "      <td>-2.107329</td>\n",
              "      <td>-1.590458</td>\n",
              "      <td>-2.120659</td>\n",
              "      <td>-0.574226</td>\n",
              "      <td>-1.629450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.897514</td>\n",
              "      <td>-0.868659</td>\n",
              "      <td>-1.020673</td>\n",
              "      <td>0.202644</td>\n",
              "      <td>-0.934192</td>\n",
              "      <td>0.964952</td>\n",
              "      <td>0.098735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.654216</td>\n",
              "      <td>0.775491</td>\n",
              "      <td>0.311048</td>\n",
              "      <td>1.547120</td>\n",
              "      <td>0.507326</td>\n",
              "      <td>2.261650</td>\n",
              "      <td>1.682063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.970800</td>\n",
              "      <td>5.679692</td>\n",
              "      <td>7.539374</td>\n",
              "      <td>8.241555</td>\n",
              "      <td>6.293280</td>\n",
              "      <td>7.249034</td>\n",
              "      <td>7.411633</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2db502fd-284d-4ea5-b6b1-6ffad46f9d4e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2db502fd-284d-4ea5-b6b1-6ffad46f9d4e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2db502fd-284d-4ea5-b6b1-6ffad46f9d4e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5b53fc7a-4638-4037-a7e9-994bf39eeb68\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5b53fc7a-4638-4037-a7e9-994bf39eeb68')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5b53fc7a-4638-4037-a7e9-994bf39eeb68 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2828.489220146718,\n        \"min\": -7.9980736,\n        \"max\": 8000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.747801801669379,\n          -0.89751402,\n          8000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2828.6150171138556,\n        \"min\": -8.283002,\n        \"max\": 8000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.7610193750192439,\n          -0.868658975,\n          8000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sweetness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2828.4567956678434,\n        \"min\": -6.4340215,\n        \"max\": 8000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.7702241042843923,\n          -1.0206731,\n          8000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Softness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2828.253863829764,\n        \"min\": -6.9593196,\n        \"max\": 8000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.014440881038258795,\n          0.20264395,\n          8000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HarvestTime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2828.5600581614904,\n        \"min\": -7.5700083,\n        \"max\": 8000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          -0.7512883019195963,\n          -0.93419198,\n          8000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ripeness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2828.1586188491356,\n        \"min\": -7.4231553,\n        \"max\": 8000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.7810983560473437,\n          0.96495169,\n          8000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Acidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2828.347741846063,\n        \"min\": -8.226977,\n        \"max\": 8000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.008725080184739966,\n          0.09873514,\n          8000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(data)[:,:-1].astype(np.float64)\n",
        "\n",
        "Y = np.array(data['Quality'] == 'Good').astype('int')"
      ],
      "metadata": {
        "id": "ZNwoPLSjc6Wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, X[1])\n",
        "\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzDozfhgdvFs",
        "outputId": "b38e9dfb-fcf9-4e5c-c685-c26efe97415e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8000, 7) [-2.4097514   0.48686993  0.34692144 -2.4950993  -0.8922133   2.0675488\n",
            "  0.30732512]\n",
            "(8000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arb = np.random.randint(0,8000)\n",
        "\n",
        "print(arb)\n",
        "print(data.iloc[arb])\n",
        "print(Y[arb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2zytir1fnW4",
        "outputId": "bfc1ef1e-c8b2-41c3-e399-1814dc0bc84f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5561\n",
            "Size           2.874354\n",
            "Weight          0.23028\n",
            "Sweetness     -2.674152\n",
            "Softness       3.740902\n",
            "HarvestTime    3.485324\n",
            "Ripeness       2.002497\n",
            "Acidity          2.1403\n",
            "Quality            Good\n",
            "Name: 5561, dtype: object\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We start our data preprocessing and actual ML coding here\n",
        "\n",
        "m = X.shape[0]\n",
        "n = X.shape[1]\n",
        "\n",
        "print(f\"Training examples: {m}, Features: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiC9mPjBg0y-",
        "outputId": "15681479-40b5-4681-c9a2-3a3424921376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training examples: 8000, Features: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a normalization function\n",
        "# Need some clarification on this. Remember to ask\n",
        "def normalize(data):\n",
        "    mean = np.mean(data, axis=0, keepdims=True)\n",
        "    # print(mean)\n",
        "    std = np.std(data, axis=0, keepdims=True)\n",
        "    # print(std)\n",
        "    data_normalized = (data - mean)/std\n",
        "    return data_normalized\n"
      ],
      "metadata": {
        "id": "-Vw2V7pWiyEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_norm = normalize(X)"
      ],
      "metadata": {
        "id": "efOwWDsWi49D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X[10], X_norm[10], Y[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpS3AVM8i808",
        "outputId": "8445aff7-5853-4510-d7d7-d9cfb57d5cd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.5878931   1.4466584   0.13883868 -2.8589776  -1.7612225   2.4337273\n",
            "  1.7631273 ] [-0.39332156  1.09518243  0.46658489 -1.37744168 -0.50584322  0.78169633\n",
            "  0.76500432] 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = [[1, 2, 3, 4, 5, 6], [-1, -2, -3, -4, -5, -6]]\n",
        "\n",
        "np.mean(a, axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxCNq7XOjzik",
        "outputId": "45c4651d-3816-499f-d630-d9c2267bf4f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenating X with a column of ones\n",
        "def concatenator(X):\n",
        "    m = X.shape[0]\n",
        "    arb = np.hstack((np.ones([m,1]),X))\n",
        "    print(f\"The data now has a column of ones in front. It went from dimensions {X.shape} to {arb.shape}\")\n",
        "    return arb"
      ],
      "metadata": {
        "id": "sv3BLnEOkOw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split to train and test\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_norm, Y, test_size=0.20, random_state=42)\n",
        "Y_train = Y_train.reshape(-1,1)\n",
        "Y_test = Y_test.reshape(-1,1)\n",
        "print(\"The shape of the training set feature matrix is:\", X_train.shape)\n",
        "print(\"The shape of the training label vector is:\", Y_train.shape)\n",
        "print(\"The shape of the test set feature matrix is:\", X_test.shape)\n",
        "print(\"The shape of the test label vector is:\", Y_test.shape)\n",
        "\n",
        "print(np.sum((Y_train==0).astype(int)))\n",
        "print(np.sum((Y_test==0).astype(int)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wG3TO4JalSvL",
        "outputId": "5e9fd261-a6d0-4f2e-e64d-35b633831f38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the training set feature matrix is: (6400, 7)\n",
            "The shape of the training label vector is: (6400, 1)\n",
            "The shape of the test set feature matrix is: (1600, 7)\n",
            "The shape of the test label vector is: (1600, 1)\n",
            "3213\n",
            "781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_n = concatenator(X_train)\n",
        "X_test_n = concatenator(X_test)\n",
        "\n",
        "print(X_train_n.shape)\n",
        "print(X_test_n.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42fsFVpgldPA",
        "outputId": "a16f5275-b504-47f9-b826-e54586856cc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The data now has a column of ones in front. It went from dimensions (6400, 7) to (6400, 8)\n",
            "The data now has a column of ones in front. It went from dimensions (1600, 7) to (1600, 8)\n",
            "(6400, 8)\n",
            "(1600, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([1, -1, 2, -3])\n",
        "\n",
        "print((a > 0).astype('int'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UsRADnVqoC-",
        "outputId": "b0153e78-10e5-419e-c3bd-4cf6fb60476c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient initializer\n",
        "def initializer(n):\n",
        "    theta = np.zeros((n,1))\n",
        "    return theta\n",
        "\n",
        "# Implementation of sigmoid function\n",
        "def step(z):\n",
        "    return (z > 0).astype('int')\n",
        "\n",
        "def sig(z):\n",
        "    return 1/(1 + np.exp(-z))\n",
        "\n",
        "# Implementation of hypothesis\n",
        "def hypothesis(X, theta):\n",
        "    h = np.dot(X, theta)\n",
        "    return step(h)\n",
        "\n",
        "# Implementation of cost function\n",
        "def cost(X, y, theta, lam):\n",
        "    m = X.shape[0]\n",
        "    h = hypothesis(X, theta)\n",
        "    arb = (1 - y * h) > 0\n",
        "    J = np.sum(arb) / m + (lam / (2*m)) * np.dot(theta.T, theta)\n",
        "    J = J.item()\n",
        "    return J\n",
        "\n",
        "# Gradient Calculations\n",
        "def grad(X, y, theta, lam):\n",
        "    m = X.shape[0]\n",
        "    n = X.shape[1]\n",
        "    h = hypothesis(X, theta)\n",
        "    dtheta = np.dot(X.T, (h-y)) / m\n",
        "\n",
        "    arb = np.zeros((n,1))\n",
        "    arb[1:] = theta[1:]\n",
        "    dtheta = dtheta + (lam / m) * arb\n",
        "    return dtheta"
      ],
      "metadata": {
        "id": "-ppEkDprllLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create prediction function\n",
        "\n",
        "def predict(X, theta):\n",
        "    Yhat_prob = step(np.matmul(X, theta))\n",
        "    Yhat = np.round(Yhat_prob).astype(int)\n",
        "    return Yhat, Yhat_prob\n",
        "\n",
        "# Create prediction function, this is for\n",
        "\n",
        "def predictor(X, theta):\n",
        "    Yhat_prob = step(theta[0] + np.dot(X, theta[1:]))\n",
        "    Yhat = np.round(Yhat_prob).astype(int)\n",
        "    return Yhat, Yhat_prob"
      ],
      "metadata": {
        "id": "vm8HMJqxlnDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the gradient descent optimizer function\n",
        "\n",
        "def gradient_descent(X, Y, X_test, Y_test, theta, alpha, epoch, batch_size, lam):\n",
        "    i=0\n",
        "    RMSE = 1\n",
        "    m = X.shape[0]\n",
        "    blocks = np.ceil(m / batch_size).astype('int')\n",
        "\n",
        "    cost_history=[]\n",
        "    test_acc_history = []\n",
        "    train_acc_history = []\n",
        "\n",
        "    J = cost(X, Y, theta, lam)\n",
        "\n",
        "    cost_history.append(J)\n",
        "\n",
        "    Yhat, _ = predict(X, theta)\n",
        "    train_accuracy = accuracy_score(Yhat, Y_train)\n",
        "    train_acc_history.append(train_accuracy)\n",
        "\n",
        "    Yhat, _ = predict(X_test, theta)\n",
        "    test_accuracy = accuracy_score(Yhat, Y_test)\n",
        "    test_acc_history.append(test_accuracy)\n",
        "\n",
        "    # while (i<max_iter):\n",
        "    #     print(f\"Iteration count: {i} / {max_iter}\", end = '\\r')\n",
        "    #     J = cost(X, Y, theta, lam)\n",
        "    #     dtheta = grad(X, Y, theta, lam)\n",
        "    #     theta = theta - alpha * dtheta\n",
        "\n",
        "    #     cost_history.append(J)\n",
        "\n",
        "    #     Yhat, _ = predict(X, theta)\n",
        "    #     train_accuracy = accuracy_score(Yhat, Y_train)\n",
        "    #     train_acc_history.append(train_accuracy)\n",
        "\n",
        "    #     Yhat, _ = predict(X_test, theta)\n",
        "    #     test_accuracy = accuracy_score(Yhat, Y_test)\n",
        "    #     test_acc_history.append(test_accuracy)\n",
        "\n",
        "    for i in range(epoch):\n",
        "        print(f\"Epoch number: {i} / {epoch}\")\n",
        "\n",
        "        print(f\"Cost: {J}, Train accuracy: {train_accuracy * 100} %, Test accuracy: {test_accuracy * 100} %\")\n",
        "\n",
        "\n",
        "\n",
        "        for k in range(blocks):\n",
        "            # print(f\"Block count: {k*batch_size} / {m}\")\n",
        "\n",
        "            if (k+1) == blocks:\n",
        "                X_curr = X[(k*batch_size):,:]\n",
        "                Y_curr = Y[(k*batch_size):,:]\n",
        "            else:\n",
        "                X_curr = X[(k*batch_size):((k+1)*batch_size),:]\n",
        "                Y_curr = Y[(k*batch_size):((k+1)*batch_size),:]\n",
        "\n",
        "            J = cost(X_curr, Y_curr, theta, lam)\n",
        "            dtheta = grad(X_curr, Y_curr, theta, lam)\n",
        "            theta = theta - alpha * dtheta\n",
        "\n",
        "            cost_history.append(J)\n",
        "\n",
        "            Yhat, _ = predict(X, theta)\n",
        "            train_accuracy = accuracy_score(Yhat, Y_train)\n",
        "            train_acc_history.append(train_accuracy)\n",
        "\n",
        "            Yhat, _ = predict(X_test, theta)\n",
        "            test_accuracy = accuracy_score(Yhat, Y_test)\n",
        "            test_acc_history.append(test_accuracy)\n",
        "\n",
        "\n",
        "    return cost_history, train_acc_history, test_acc_history, theta, i"
      ],
      "metadata": {
        "id": "JlxYtx7YlqsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LogRegModel(X_train, Y_train, X_test, Y_test, alpha, epoch, batch_size, lam):\n",
        "\n",
        "    n = X_train.shape[1]\n",
        "    theta = initializer(n)\n",
        "    cost_history, train_acc_history, test_acc_history, theta, i = gradient_descent(X_train, Y_train, X_test, Y_test, theta, alpha, epoch, batch_size, lam)\n",
        "    Yhat_train, _ = predict(X_train, theta)\n",
        "    Yhat, _ = predict(X_test, theta)\n",
        "\n",
        "    train_acc = accuracy_score(Y_train, Yhat_train)\n",
        "    test_acc = accuracy_score(Y_test, Yhat)\n",
        "    conf_matrix = confusion_matrix(Y_test, Yhat, normalize = None)\n",
        "\n",
        "    model = {'weights': theta,\n",
        "            'train_accuracy': train_acc,\n",
        "            'test_accuracy': test_acc,\n",
        "            'confusion_matrix': conf_matrix,\n",
        "            'cost_history': cost_history,\n",
        "             'train_history': train_acc_history,\n",
        "             'test_history': test_acc_history}\n",
        "    return model"
      ],
      "metadata": {
        "id": "RUaRfJOvmsKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model function by training a classifier\n",
        "\n",
        "l = 0\n",
        "alpha = 0.1\n",
        "epoch = 1000\n",
        "batch_size = 6400\n",
        "\n",
        "model_0 = LogRegModel(X_train_n, Y_train, X_test_n, Y_test, alpha, epoch, batch_size, l)\n",
        "print('Training completed!')\n",
        "\n",
        "print(model_0['confusion_matrix'])\n",
        "print(f\"Train accuracy: {model_0['train_accuracy'] * 100} %, Test accuracy: {model_0['test_accuracy'] * 100} %\")\n",
        "\n",
        "# Viewing the cost evolution over time of the trained model\n",
        "\n",
        "cost_values = model_0['cost_history']\n",
        "plt.plot(list(range(len(cost_values))),cost_values)\n",
        "plt.title('Evolution of the cost by iteration')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Cost');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kkngkk6Fls5e",
        "outputId": "c6cee8c5-60db-4df4-9784-a44b01a78bc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch number: 0 / 1000\n",
            "Cost: 1.0, Train accuracy: 50.20312500000001 %, Test accuracy: 48.8125 %\n",
            "Epoch number: 1 / 1000\n",
            "Cost: 1.0, Train accuracy: 65.640625 %, Test accuracy: 67.1875 %\n",
            "Epoch number: 2 / 1000\n",
            "Cost: 0.503125, Train accuracy: 84.75 %, Test accuracy: 85.6875 %\n",
            "Epoch number: 3 / 1000\n",
            "Cost: 0.53546875, Train accuracy: 86.765625 %, Test accuracy: 86.9375 %\n",
            "Epoch number: 4 / 1000\n",
            "Cost: 0.54859375, Train accuracy: 87.25 %, Test accuracy: 87.5625 %\n",
            "Epoch number: 5 / 1000\n",
            "Cost: 0.5565625, Train accuracy: 87.390625 %, Test accuracy: 87.8125 %\n",
            "Epoch number: 6 / 1000\n",
            "Cost: 0.56078125, Train accuracy: 87.671875 %, Test accuracy: 87.625 %\n",
            "Epoch number: 7 / 1000\n",
            "Cost: 0.55984375, Train accuracy: 87.59375 %, Test accuracy: 87.375 %\n",
            "Epoch number: 8 / 1000\n",
            "Cost: 0.56234375, Train accuracy: 87.75 %, Test accuracy: 87.6875 %\n",
            "Epoch number: 9 / 1000\n",
            "Cost: 0.56015625, Train accuracy: 87.484375 %, Test accuracy: 87.375 %\n",
            "Epoch number: 10 / 1000\n",
            "Cost: 0.5665625, Train accuracy: 87.78125 %, Test accuracy: 88.125 %\n",
            "Epoch number: 11 / 1000\n",
            "Cost: 0.5584375, Train accuracy: 86.015625 %, Test accuracy: 85.875 %\n",
            "Epoch number: 12 / 1000\n",
            "Cost: 0.5903125, Train accuracy: 81.125 %, Test accuracy: 82.375 %\n",
            "Epoch number: 13 / 1000\n",
            "Cost: 0.578125, Train accuracy: 62.609375 %, Test accuracy: 63.375 %\n",
            "Epoch number: 14 / 1000\n",
            "Cost: 0.74578125, Train accuracy: 68.984375 %, Test accuracy: 70.375 %\n",
            "Epoch number: 15 / 1000\n",
            "Cost: 0.66953125, Train accuracy: 85.3125 %, Test accuracy: 85.875 %\n",
            "Epoch number: 16 / 1000\n",
            "Cost: 0.540625, Train accuracy: 87.125 %, Test accuracy: 87.25 %\n",
            "Epoch number: 17 / 1000\n",
            "Cost: 0.5496875, Train accuracy: 87.328125 %, Test accuracy: 87.6875 %\n",
            "Epoch number: 18 / 1000\n",
            "Cost: 0.55890625, Train accuracy: 87.625 %, Test accuracy: 87.8125 %\n",
            "Epoch number: 19 / 1000\n",
            "Cost: 0.55890625, Train accuracy: 87.5625 %, Test accuracy: 87.875 %\n",
            "Epoch number: 20 / 1000\n",
            "Cost: 0.56234375, Train accuracy: 87.71875 %, Test accuracy: 87.6875 %\n",
            "Epoch number: 21 / 1000\n",
            "Cost: 0.5615625, Train accuracy: 87.421875 %, Test accuracy: 87.5 %\n",
            "Epoch number: 22 / 1000\n",
            "Cost: 0.56609375, Train accuracy: 87.859375 %, Test accuracy: 88.1875 %\n",
            "Epoch number: 23 / 1000\n",
            "Cost: 0.5596875, Train accuracy: 86.671875 %, Test accuracy: 86.5625 %\n",
            "Epoch number: 24 / 1000\n",
            "Cost: 0.58078125, Train accuracy: 84.125 %, Test accuracy: 85.1875 %\n",
            "Epoch number: 25 / 1000\n",
            "Cost: 0.56515625, Train accuracy: 63.796875 %, Test accuracy: 64.875 %\n",
            "Epoch number: 26 / 1000\n",
            "Cost: 0.7475, Train accuracy: 65.5 %, Test accuracy: 67.1875 %\n",
            "Epoch number: 27 / 1000\n",
            "Cost: 0.69171875, Train accuracy: 84.796875 %, Test accuracy: 84.8125 %\n",
            "Epoch number: 28 / 1000\n",
            "Cost: 0.53953125, Train accuracy: 86.875 %, Test accuracy: 87.0625 %\n",
            "Epoch number: 29 / 1000\n",
            "Cost: 0.5471875, Train accuracy: 87.390625 %, Test accuracy: 87.625 %\n",
            "Epoch number: 30 / 1000\n",
            "Cost: 0.558125, Train accuracy: 87.5625 %, Test accuracy: 87.875 %\n",
            "Epoch number: 31 / 1000\n",
            "Cost: 0.55921875, Train accuracy: 87.671875 %, Test accuracy: 87.6875 %\n",
            "Epoch number: 32 / 1000\n",
            "Cost: 0.56109375, Train accuracy: 87.75 %, Test accuracy: 87.6875 %\n",
            "Epoch number: 33 / 1000\n",
            "Cost: 0.56109375, Train accuracy: 87.484375 %, Test accuracy: 87.5625 %\n",
            "Epoch number: 34 / 1000\n",
            "Cost: 0.56546875, Train accuracy: 87.84375 %, Test accuracy: 88.25 %\n",
            "Epoch number: 35 / 1000\n",
            "Cost: 0.560625, Train accuracy: 87.0625 %, Test accuracy: 87.125 %\n",
            "Epoch number: 36 / 1000\n",
            "Cost: 0.57375, Train accuracy: 86.46875 %, Test accuracy: 86.875 %\n",
            "Epoch number: 37 / 1000\n",
            "Cost: 0.5534375, Train accuracy: 70.96875 %, Test accuracy: 70.6875 %\n",
            "Epoch number: 38 / 1000\n",
            "Cost: 0.7225, Train accuracy: 62.671875 %, Test accuracy: 63.4375 %\n",
            "Epoch number: 39 / 1000\n",
            "Cost: 0.69890625, Train accuracy: 81.375 %, Test accuracy: 82.0625 %\n",
            "Epoch number: 40 / 1000\n",
            "Cost: 0.5659375, Train accuracy: 86.546875 %, Test accuracy: 87.0 %\n",
            "Epoch number: 41 / 1000\n",
            "Cost: 0.53875, Train accuracy: 87.125 %, Test accuracy: 87.3125 %\n",
            "Epoch number: 42 / 1000\n",
            "Cost: 0.56078125, Train accuracy: 87.703125 %, Test accuracy: 87.625 %\n",
            "Epoch number: 43 / 1000\n",
            "Cost: 0.556875, Train accuracy: 87.34375 %, Test accuracy: 87.5 %\n",
            "Epoch number: 44 / 1000\n",
            "Cost: 0.56578125, Train accuracy: 87.703125 %, Test accuracy: 88.1875 %\n",
            "Epoch number: 45 / 1000\n",
            "Cost: 0.55828125, Train accuracy: 87.140625 %, Test accuracy: 87.0625 %\n",
            "Epoch number: 46 / 1000\n",
            "Cost: 0.57375, Train accuracy: 87.484375 %, Test accuracy: 87.75 %\n",
            "Epoch number: 47 / 1000\n",
            "Cost: 0.55015625, Train accuracy: 81.265625 %, Test accuracy: 81.25 %\n",
            "Epoch number: 48 / 1000\n",
            "Cost: 0.63734375, Train accuracy: 72.296875 %, Test accuracy: 73.375 %\n",
            "Epoch number: 49 / 1000\n",
            "Cost: 0.64234375, Train accuracy: 69.203125 %, Test accuracy: 69.1875 %\n",
            "Epoch number: 50 / 1000\n",
            "Cost: 0.6784375, Train accuracy: 79.234375 %, Test accuracy: 80.9375 %\n",
            "Epoch number: 51 / 1000\n",
            "Cost: 0.589375, Train accuracy: 85.984375 %, Test accuracy: 86.875 %\n",
            "Epoch number: 52 / 1000\n",
            "Cost: 0.55125, Train accuracy: 87.296875 %, Test accuracy: 87.6875 %\n",
            "Epoch number: 53 / 1000\n",
            "Cost: 0.5540625, Train accuracy: 87.1875 %, Test accuracy: 87.1875 %\n",
            "Epoch number: 54 / 1000\n",
            "Cost: 0.56453125, Train accuracy: 87.703125 %, Test accuracy: 87.875 %\n",
            "Epoch number: 55 / 1000\n",
            "Cost: 0.55734375, Train accuracy: 87.0625 %, Test accuracy: 87.3125 %\n",
            "Epoch number: 56 / 1000\n",
            "Cost: 0.57296875, Train accuracy: 87.546875 %, Test accuracy: 87.875 %\n",
            "Epoch number: 57 / 1000\n",
            "Cost: 0.55, Train accuracy: 82.078125 %, Test accuracy: 82.5625 %\n",
            "Epoch number: 58 / 1000\n",
            "Cost: 0.62859375, Train accuracy: 73.921875 %, Test accuracy: 75.25 %\n",
            "Epoch number: 59 / 1000\n",
            "Cost: 0.63015625, Train accuracy: 67.625 %, Test accuracy: 68.375 %\n",
            "Epoch number: 60 / 1000\n",
            "Cost: 0.69515625, Train accuracy: 77.4375 %, Test accuracy: 79.875 %\n",
            "Epoch number: 61 / 1000\n",
            "Cost: 0.60390625, Train accuracy: 85.96875 %, Test accuracy: 86.625 %\n",
            "Epoch number: 62 / 1000\n",
            "Cost: 0.54640625, Train accuracy: 87.3125 %, Test accuracy: 87.5625 %\n",
            "Epoch number: 63 / 1000\n",
            "Cost: 0.55390625, Train accuracy: 87.328125 %, Test accuracy: 87.5625 %\n",
            "Epoch number: 64 / 1000\n",
            "Cost: 0.561875, Train accuracy: 87.78125 %, Test accuracy: 88.0 %\n",
            "Epoch number: 65 / 1000\n",
            "Cost: 0.55859375, Train accuracy: 87.34375 %, Test accuracy: 87.4375 %\n",
            "Epoch number: 66 / 1000\n",
            "Cost: 0.56703125, Train accuracy: 87.625 %, Test accuracy: 88.25 %\n",
            "Epoch number: 67 / 1000\n",
            "Cost: 0.55734375, Train accuracy: 85.828125 %, Test accuracy: 85.5 %\n",
            "Epoch number: 68 / 1000\n",
            "Cost: 0.590625, Train accuracy: 82.84375 %, Test accuracy: 84.0625 %\n",
            "Epoch number: 69 / 1000\n",
            "Cost: 0.56875, Train accuracy: 66.140625 %, Test accuracy: 66.6875 %\n",
            "Epoch number: 70 / 1000\n",
            "Cost: 0.7315625, Train accuracy: 68.328125 %, Test accuracy: 69.6875 %\n",
            "Epoch number: 71 / 1000\n",
            "Cost: 0.67140625, Train accuracy: 84.53125 %, Test accuracy: 84.5 %\n",
            "Epoch number: 72 / 1000\n",
            "Cost: 0.5453125, Train accuracy: 86.984375 %, Test accuracy: 87.25 %\n",
            "Epoch number: 73 / 1000\n",
            "Cost: 0.54734375, Train accuracy: 87.359375 %, Test accuracy: 87.75 %\n",
            "Epoch number: 74 / 1000\n",
            "Cost: 0.56046875, Train accuracy: 87.734375 %, Test accuracy: 87.8125 %\n",
            "Epoch number: 75 / 1000\n",
            "Cost: 0.55828125, Train accuracy: 87.5 %, Test accuracy: 87.5 %\n",
            "Epoch number: 76 / 1000\n",
            "Cost: 0.56421875, Train accuracy: 87.71875 %, Test accuracy: 87.9375 %\n",
            "Epoch number: 77 / 1000\n",
            "Cost: 0.559375, Train accuracy: 87.28125 %, Test accuracy: 87.1875 %\n",
            "Epoch number: 78 / 1000\n",
            "Cost: 0.570625, Train accuracy: 87.53125 %, Test accuracy: 87.875 %\n",
            "Epoch number: 79 / 1000\n",
            "Cost: 0.5534375, Train accuracy: 82.015625 %, Test accuracy: 82.25 %\n",
            "Epoch number: 80 / 1000\n",
            "Cost: 0.63046875, Train accuracy: 70.9375 %, Test accuracy: 72.1875 %\n",
            "Epoch number: 81 / 1000\n",
            "Cost: 0.64921875, Train accuracy: 65.953125 %, Test accuracy: 66.6875 %\n",
            "Epoch number: 82 / 1000\n",
            "Cost: 0.700625, Train accuracy: 78.5 %, Test accuracy: 80.625 %\n",
            "Epoch number: 83 / 1000\n",
            "Cost: 0.59703125, Train accuracy: 86.109375 %, Test accuracy: 86.75 %\n",
            "Epoch number: 84 / 1000\n",
            "Cost: 0.54609375, Train accuracy: 87.21875 %, Test accuracy: 87.3125 %\n",
            "Epoch number: 85 / 1000\n",
            "Cost: 0.554375, Train accuracy: 87.4375 %, Test accuracy: 87.75 %\n",
            "Epoch number: 86 / 1000\n",
            "Cost: 0.56, Train accuracy: 87.6875 %, Test accuracy: 87.875 %\n",
            "Epoch number: 87 / 1000\n",
            "Cost: 0.5590625, Train accuracy: 87.484375 %, Test accuracy: 87.5625 %\n",
            "Epoch number: 88 / 1000\n",
            "Cost: 0.5640625, Train accuracy: 87.796875 %, Test accuracy: 88.125 %\n",
            "Epoch number: 89 / 1000\n",
            "Cost: 0.55984375, Train accuracy: 87.171875 %, Test accuracy: 87.125 %\n",
            "Epoch number: 90 / 1000\n",
            "Cost: 0.57203125, Train accuracy: 87.28125 %, Test accuracy: 87.4375 %\n",
            "Epoch number: 91 / 1000\n",
            "Cost: 0.55171875, Train accuracy: 75.421875 %, Test accuracy: 74.9375 %\n",
            "Epoch number: 92 / 1000\n",
            "Cost: 0.68796875, Train accuracy: 63.578125 %, Test accuracy: 64.5625 %\n",
            "Epoch number: 93 / 1000\n",
            "Cost: 0.69484375, Train accuracy: 76.09375 %, Test accuracy: 76.0625 %\n",
            "Epoch number: 94 / 1000\n",
            "Cost: 0.6140625, Train accuracy: 85.578125 %, Test accuracy: 86.875 %\n",
            "Epoch number: 95 / 1000\n",
            "Cost: 0.53625, Train accuracy: 87.046875 %, Test accuracy: 87.4375 %\n",
            "Epoch number: 96 / 1000\n",
            "Cost: 0.55828125, Train accuracy: 87.40625 %, Test accuracy: 87.75 %\n",
            "Epoch number: 97 / 1000\n",
            "Cost: 0.55859375, Train accuracy: 87.5625 %, Test accuracy: 87.5625 %\n",
            "Epoch number: 98 / 1000\n",
            "Cost: 0.561875, Train accuracy: 87.671875 %, Test accuracy: 87.8125 %\n",
            "Epoch number: 99 / 1000\n",
            "Cost: 0.56078125, Train accuracy: 87.4375 %, Test accuracy: 87.4375 %\n",
            "Epoch number: 100 / 1000\n",
            "Cost: 0.5671875, Train accuracy: 87.71875 %, Test accuracy: 88.125 %\n",
            "Epoch number: 101 / 1000\n",
            "Cost: 0.5584375, Train accuracy: 85.921875 %, Test accuracy: 85.8125 %\n",
            "Epoch number: 102 / 1000\n",
            "Cost: 0.5915625, Train accuracy: 81.53125 %, Test accuracy: 82.8125 %\n",
            "Epoch number: 103 / 1000\n",
            "Cost: 0.5746875, Train accuracy: 63.4375 %, Test accuracy: 64.75 %\n",
            "Epoch number: 104 / 1000\n",
            "Cost: 0.7434375, Train accuracy: 68.78125 %, Test accuracy: 70.125 %\n",
            "Epoch number: 105 / 1000\n",
            "Cost: 0.66984375, Train accuracy: 85.25 %, Test accuracy: 85.75 %\n",
            "Epoch number: 106 / 1000\n",
            "Cost: 0.54125, Train accuracy: 87.09375 %, Test accuracy: 87.375 %\n",
            "Epoch number: 107 / 1000\n",
            "Cost: 0.54890625, Train accuracy: 87.25 %, Test accuracy: 87.625 %\n",
            "Epoch number: 108 / 1000\n",
            "Cost: 0.55984375, Train accuracy: 87.703125 %, Test accuracy: 87.75 %\n",
            "Epoch number: 109 / 1000\n",
            "Cost: 0.55890625, Train accuracy: 87.515625 %, Test accuracy: 87.6875 %\n",
            "Epoch number: 110 / 1000\n",
            "Cost: 0.563125, Train accuracy: 87.703125 %, Test accuracy: 87.75 %\n",
            "Epoch number: 111 / 1000\n",
            "Cost: 0.560625, Train accuracy: 87.4375 %, Test accuracy: 87.5 %\n",
            "Epoch number: 112 / 1000\n",
            "Cost: 0.5671875, Train accuracy: 87.6875 %, Test accuracy: 88.125 %\n",
            "Epoch number: 113 / 1000\n",
            "Cost: 0.5584375, Train accuracy: 85.71875 %, Test accuracy: 85.5 %\n",
            "Epoch number: 114 / 1000\n",
            "Cost: 0.59328125, Train accuracy: 80.6875 %, Test accuracy: 82.0625 %\n",
            "Epoch number: 115 / 1000\n",
            "Cost: 0.58078125, Train accuracy: 62.765625 %, Test accuracy: 63.5 %\n",
            "Epoch number: 116 / 1000\n",
            "Cost: 0.74390625, Train accuracy: 69.4375 %, Test accuracy: 71.4375 %\n",
            "Epoch number: 117 / 1000\n",
            "Cost: 0.6665625, Train accuracy: 85.296875 %, Test accuracy: 85.875 %\n",
            "Epoch number: 118 / 1000\n",
            "Cost: 0.5409375, Train accuracy: 87.140625 %, Test accuracy: 87.3125 %\n",
            "Epoch number: 119 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 87.359375 %, Test accuracy: 87.75 %\n",
            "Epoch number: 120 / 1000\n",
            "Cost: 0.55921875, Train accuracy: 87.578125 %, Test accuracy: 87.8125 %\n",
            "Epoch number: 121 / 1000\n",
            "Cost: 0.5590625, Train accuracy: 87.578125 %, Test accuracy: 87.875 %\n",
            "Epoch number: 122 / 1000\n",
            "Cost: 0.5625, Train accuracy: 87.734375 %, Test accuracy: 87.5625 %\n",
            "Epoch number: 123 / 1000\n",
            "Cost: 0.56125, Train accuracy: 87.5 %, Test accuracy: 87.5625 %\n",
            "Epoch number: 124 / 1000\n",
            "Cost: 0.565625, Train accuracy: 87.953125 %, Test accuracy: 88.25 %\n",
            "Epoch number: 125 / 1000\n",
            "Cost: 0.5596875, Train accuracy: 86.90625 %, Test accuracy: 87.0 %\n",
            "Epoch number: 126 / 1000\n",
            "Cost: 0.57828125, Train accuracy: 84.546875 %, Test accuracy: 85.6875 %\n",
            "Epoch number: 127 / 1000\n",
            "Cost: 0.5621875, Train accuracy: 63.74999999999999 %, Test accuracy: 65.0 %\n",
            "Epoch number: 128 / 1000\n",
            "Cost: 0.74953125, Train accuracy: 64.8125 %, Test accuracy: 66.4375 %\n",
            "Epoch number: 129 / 1000\n",
            "Cost: 0.6959375, Train accuracy: 84.625 %, Test accuracy: 84.875 %\n",
            "Epoch number: 130 / 1000\n",
            "Cost: 0.54046875, Train accuracy: 86.8125 %, Test accuracy: 87.0625 %\n",
            "Epoch number: 131 / 1000\n",
            "Cost: 0.54734375, Train accuracy: 87.375 %, Test accuracy: 87.625 %\n",
            "Epoch number: 132 / 1000\n",
            "Cost: 0.55734375, Train accuracy: 87.578125 %, Test accuracy: 87.875 %\n",
            "Epoch number: 133 / 1000\n",
            "Cost: 0.5590625, Train accuracy: 87.609375 %, Test accuracy: 87.625 %\n",
            "Epoch number: 134 / 1000\n",
            "Cost: 0.56171875, Train accuracy: 87.75 %, Test accuracy: 87.8125 %\n",
            "Epoch number: 135 / 1000\n",
            "Cost: 0.56125, Train accuracy: 87.46875 %, Test accuracy: 87.625 %\n",
            "Epoch number: 136 / 1000\n",
            "Cost: 0.5653125, Train accuracy: 87.875 %, Test accuracy: 88.25 %\n",
            "Epoch number: 137 / 1000\n",
            "Cost: 0.56046875, Train accuracy: 87.015625 %, Test accuracy: 87.0625 %\n",
            "Epoch number: 138 / 1000\n",
            "Cost: 0.5734375, Train accuracy: 86.84375 %, Test accuracy: 87.25 %\n",
            "Epoch number: 139 / 1000\n",
            "Cost: 0.553125, Train accuracy: 72.625 %, Test accuracy: 72.25 %\n",
            "Epoch number: 140 / 1000\n",
            "Cost: 0.710625, Train accuracy: 62.734375 %, Test accuracy: 63.375 %\n",
            "Epoch number: 141 / 1000\n",
            "Cost: 0.6984375, Train accuracy: 80.171875 %, Test accuracy: 80.75 %\n",
            "Epoch number: 142 / 1000\n",
            "Cost: 0.5784375, Train accuracy: 86.125 %, Test accuracy: 86.9375 %\n",
            "Epoch number: 143 / 1000\n",
            "Cost: 0.53734375, Train accuracy: 86.96875 %, Test accuracy: 87.25 %\n",
            "Epoch number: 144 / 1000\n",
            "Cost: 0.56171875, Train accuracy: 87.78125 %, Test accuracy: 87.8125 %\n",
            "Epoch number: 145 / 1000\n",
            "Cost: 0.5559375, Train accuracy: 87.34375 %, Test accuracy: 87.5 %\n",
            "Epoch number: 146 / 1000\n",
            "Cost: 0.56640625, Train accuracy: 87.6875 %, Test accuracy: 88.1875 %\n",
            "Epoch number: 147 / 1000\n",
            "Cost: 0.5578125, Train accuracy: 87.078125 %, Test accuracy: 87.0 %\n",
            "Epoch number: 148 / 1000\n",
            "Cost: 0.57484375, Train accuracy: 87.3125 %, Test accuracy: 87.5625 %\n",
            "Epoch number: 149 / 1000\n",
            "Cost: 0.54984375, Train accuracy: 80.0625 %, Test accuracy: 79.5625 %\n",
            "Epoch number: 150 / 1000\n",
            "Cost: 0.648125, Train accuracy: 71.015625 %, Test accuracy: 72.3125 %\n",
            "Epoch number: 151 / 1000\n",
            "Cost: 0.6503125, Train accuracy: 70.859375 %, Test accuracy: 70.4375 %\n",
            "Epoch number: 152 / 1000\n",
            "Cost: 0.66453125, Train accuracy: 80.734375 %, Test accuracy: 82.0 %\n",
            "Epoch number: 153 / 1000\n",
            "Cost: 0.57640625, Train accuracy: 86.09375 %, Test accuracy: 87.1875 %\n",
            "Epoch number: 154 / 1000\n",
            "Cost: 0.55421875, Train accuracy: 87.328125 %, Test accuracy: 87.5 %\n",
            "Epoch number: 155 / 1000\n",
            "Cost: 0.55390625, Train accuracy: 87.140625 %, Test accuracy: 87.125 %\n",
            "Epoch number: 156 / 1000\n",
            "Cost: 0.56625, Train accuracy: 87.765625 %, Test accuracy: 87.9375 %\n",
            "Epoch number: 157 / 1000\n",
            "Cost: 0.5565625, Train accuracy: 86.96875 %, Test accuracy: 87.125 %\n",
            "Epoch number: 158 / 1000\n",
            "Cost: 0.57578125, Train accuracy: 86.984375 %, Test accuracy: 87.875 %\n",
            "Epoch number: 159 / 1000\n",
            "Cost: 0.549375, Train accuracy: 80.03125 %, Test accuracy: 79.75 %\n",
            "Epoch number: 160 / 1000\n",
            "Cost: 0.648125, Train accuracy: 71.484375 %, Test accuracy: 72.6875 %\n",
            "Epoch number: 161 / 1000\n",
            "Cost: 0.645625, Train accuracy: 71.078125 %, Test accuracy: 70.75 %\n",
            "Epoch number: 162 / 1000\n",
            "Cost: 0.664375, Train accuracy: 80.421875 %, Test accuracy: 81.8125 %\n",
            "Epoch number: 163 / 1000\n",
            "Cost: 0.57890625, Train accuracy: 85.96875 %, Test accuracy: 87.125 %\n",
            "Epoch number: 164 / 1000\n",
            "Cost: 0.555625, Train accuracy: 87.3125 %, Test accuracy: 87.5625 %\n",
            "Epoch number: 165 / 1000\n",
            "Cost: 0.55421875, Train accuracy: 87.1875 %, Test accuracy: 87.0625 %\n",
            "Epoch number: 166 / 1000\n",
            "Cost: 0.565625, Train accuracy: 87.75 %, Test accuracy: 88.0625 %\n",
            "Epoch number: 167 / 1000\n",
            "Cost: 0.55671875, Train accuracy: 86.90625 %, Test accuracy: 86.8125 %\n",
            "Epoch number: 168 / 1000\n",
            "Cost: 0.57625, Train accuracy: 86.828125 %, Test accuracy: 87.4375 %\n",
            "Epoch number: 169 / 1000\n",
            "Cost: 0.55015625, Train accuracy: 78.90625 %, Test accuracy: 78.1875 %\n",
            "Epoch number: 170 / 1000\n",
            "Cost: 0.6571875, Train accuracy: 69.96875 %, Test accuracy: 71.4375 %\n",
            "Epoch number: 171 / 1000\n",
            "Cost: 0.65640625, Train accuracy: 72.953125 %, Test accuracy: 72.6875 %\n",
            "Epoch number: 172 / 1000\n",
            "Cost: 0.64828125, Train accuracy: 82.296875 %, Test accuracy: 83.5625 %\n",
            "Epoch number: 173 / 1000\n",
            "Cost: 0.56296875, Train accuracy: 86.234375 %, Test accuracy: 87.625 %\n",
            "Epoch number: 174 / 1000\n",
            "Cost: 0.5584375, Train accuracy: 87.46875 %, Test accuracy: 87.5625 %\n",
            "Epoch number: 175 / 1000\n",
            "Cost: 0.554375, Train accuracy: 87.0 %, Test accuracy: 87.0 %\n",
            "Epoch number: 176 / 1000\n",
            "Cost: 0.56859375, Train accuracy: 87.78125 %, Test accuracy: 88.1875 %\n",
            "Epoch number: 177 / 1000\n",
            "Cost: 0.55453125, Train accuracy: 86.34375 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 178 / 1000\n",
            "Cost: 0.5840625, Train accuracy: 85.828125 %, Test accuracy: 86.5625 %\n",
            "Epoch number: 179 / 1000\n",
            "Cost: 0.55078125, Train accuracy: 74.421875 %, Test accuracy: 74.5625 %\n",
            "Epoch number: 180 / 1000\n",
            "Cost: 0.69015625, Train accuracy: 68.9375 %, Test accuracy: 70.75 %\n",
            "Epoch number: 181 / 1000\n",
            "Cost: 0.66375, Train accuracy: 79.625 %, Test accuracy: 80.0625 %\n",
            "Epoch number: 182 / 1000\n",
            "Cost: 0.58875, Train accuracy: 86.109375 %, Test accuracy: 87.5 %\n",
            "Epoch number: 183 / 1000\n",
            "Cost: 0.53890625, Train accuracy: 86.765625 %, Test accuracy: 87.25 %\n",
            "Epoch number: 184 / 1000\n",
            "Cost: 0.57109375, Train accuracy: 87.59375 %, Test accuracy: 88.25 %\n",
            "Epoch number: 185 / 1000\n",
            "Cost: 0.55140625, Train accuracy: 86.421875 %, Test accuracy: 86.4375 %\n",
            "Epoch number: 186 / 1000\n",
            "Cost: 0.581875, Train accuracy: 86.703125 %, Test accuracy: 87.5 %\n",
            "Epoch number: 187 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 81.6875 %, Test accuracy: 81.8125 %\n",
            "Epoch number: 188 / 1000\n",
            "Cost: 0.63078125, Train accuracy: 76.859375 %, Test accuracy: 78.6875 %\n",
            "Epoch number: 189 / 1000\n",
            "Cost: 0.60796875, Train accuracy: 73.296875 %, Test accuracy: 72.5 %\n",
            "Epoch number: 190 / 1000\n",
            "Cost: 0.664375, Train accuracy: 78.5625 %, Test accuracy: 80.375 %\n",
            "Epoch number: 191 / 1000\n",
            "Cost: 0.59546875, Train accuracy: 84.65625 %, Test accuracy: 85.3125 %\n",
            "Epoch number: 192 / 1000\n",
            "Cost: 0.56453125, Train accuracy: 87.0625 %, Test accuracy: 88.3125 %\n",
            "Epoch number: 193 / 1000\n",
            "Cost: 0.5471875, Train accuracy: 86.265625 %, Test accuracy: 86.75 %\n",
            "Epoch number: 194 / 1000\n",
            "Cost: 0.5825, Train accuracy: 86.953125 %, Test accuracy: 88.0625 %\n",
            "Epoch number: 195 / 1000\n",
            "Cost: 0.5490625, Train accuracy: 84.0625 %, Test accuracy: 84.0625 %\n",
            "Epoch number: 196 / 1000\n",
            "Cost: 0.60765625, Train accuracy: 81.75 %, Test accuracy: 83.3125 %\n",
            "Epoch number: 197 / 1000\n",
            "Cost: 0.5759375, Train accuracy: 73.171875 %, Test accuracy: 73.625 %\n",
            "Epoch number: 198 / 1000\n",
            "Cost: 0.68109375, Train accuracy: 73.734375 %, Test accuracy: 75.375 %\n",
            "Epoch number: 199 / 1000\n",
            "Cost: 0.631875, Train accuracy: 82.75 %, Test accuracy: 83.0 %\n",
            "Epoch number: 200 / 1000\n",
            "Cost: 0.57203125, Train accuracy: 86.5 %, Test accuracy: 87.75 %\n",
            "Epoch number: 201 / 1000\n",
            "Cost: 0.54390625, Train accuracy: 86.375 %, Test accuracy: 86.9375 %\n",
            "Epoch number: 202 / 1000\n",
            "Cost: 0.5778125, Train accuracy: 87.3125 %, Test accuracy: 88.25 %\n",
            "Epoch number: 203 / 1000\n",
            "Cost: 0.5503125, Train accuracy: 85.34375 %, Test accuracy: 85.5 %\n",
            "Epoch number: 204 / 1000\n",
            "Cost: 0.59421875, Train accuracy: 84.640625 %, Test accuracy: 85.75 %\n",
            "Epoch number: 205 / 1000\n",
            "Cost: 0.5578125, Train accuracy: 76.203125 %, Test accuracy: 75.5625 %\n",
            "Epoch number: 206 / 1000\n",
            "Cost: 0.66953125, Train accuracy: 72.984375 %, Test accuracy: 74.25 %\n",
            "Epoch number: 207 / 1000\n",
            "Cost: 0.63625, Train accuracy: 79.3125 %, Test accuracy: 79.9375 %\n",
            "Epoch number: 208 / 1000\n",
            "Cost: 0.599375, Train accuracy: 85.09375 %, Test accuracy: 86.625 %\n",
            "Epoch number: 209 / 1000\n",
            "Cost: 0.548125, Train accuracy: 85.71875 %, Test accuracy: 86.5 %\n",
            "Epoch number: 210 / 1000\n",
            "Cost: 0.5803125, Train accuracy: 87.125 %, Test accuracy: 88.1875 %\n",
            "Epoch number: 211 / 1000\n",
            "Cost: 0.5490625, Train accuracy: 85.375 %, Test accuracy: 85.8125 %\n",
            "Epoch number: 212 / 1000\n",
            "Cost: 0.5934375, Train accuracy: 85.046875 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 213 / 1000\n",
            "Cost: 0.5559375, Train accuracy: 77.703125 %, Test accuracy: 77.0625 %\n",
            "Epoch number: 214 / 1000\n",
            "Cost: 0.6578125, Train accuracy: 74.296875 %, Test accuracy: 76.125 %\n",
            "Epoch number: 215 / 1000\n",
            "Cost: 0.62859375, Train accuracy: 78.171875 %, Test accuracy: 78.4375 %\n",
            "Epoch number: 216 / 1000\n",
            "Cost: 0.61171875, Train accuracy: 84.140625 %, Test accuracy: 85.375 %\n",
            "Epoch number: 217 / 1000\n",
            "Cost: 0.55453125, Train accuracy: 85.515625 %, Test accuracy: 86.3125 %\n",
            "Epoch number: 218 / 1000\n",
            "Cost: 0.57953125, Train accuracy: 86.875 %, Test accuracy: 88.125 %\n",
            "Epoch number: 219 / 1000\n",
            "Cost: 0.549375, Train accuracy: 85.484375 %, Test accuracy: 86.0 %\n",
            "Epoch number: 220 / 1000\n",
            "Cost: 0.59171875, Train accuracy: 85.328125 %, Test accuracy: 86.125 %\n",
            "Epoch number: 221 / 1000\n",
            "Cost: 0.554375, Train accuracy: 78.0 %, Test accuracy: 77.375 %\n",
            "Epoch number: 222 / 1000\n",
            "Cost: 0.65671875, Train accuracy: 74.421875 %, Test accuracy: 76.25 %\n",
            "Epoch number: 223 / 1000\n",
            "Cost: 0.6278125, Train accuracy: 78.0 %, Test accuracy: 78.0625 %\n",
            "Epoch number: 224 / 1000\n",
            "Cost: 0.6140625, Train accuracy: 83.953125 %, Test accuracy: 85.1875 %\n",
            "Epoch number: 225 / 1000\n",
            "Cost: 0.5553125, Train accuracy: 85.625 %, Test accuracy: 86.4375 %\n",
            "Epoch number: 226 / 1000\n",
            "Cost: 0.578125, Train accuracy: 87.03125 %, Test accuracy: 88.125 %\n",
            "Epoch number: 227 / 1000\n",
            "Cost: 0.54921875, Train accuracy: 85.703125 %, Test accuracy: 86.125 %\n",
            "Epoch number: 228 / 1000\n",
            "Cost: 0.59, Train accuracy: 85.375 %, Test accuracy: 86.1875 %\n",
            "Epoch number: 229 / 1000\n",
            "Cost: 0.55421875, Train accuracy: 77.921875 %, Test accuracy: 77.1875 %\n",
            "Epoch number: 230 / 1000\n",
            "Cost: 0.65765625, Train accuracy: 74.109375 %, Test accuracy: 75.8125 %\n",
            "Epoch number: 231 / 1000\n",
            "Cost: 0.6303125, Train accuracy: 77.78125 %, Test accuracy: 77.6875 %\n",
            "Epoch number: 232 / 1000\n",
            "Cost: 0.6146875, Train accuracy: 83.96875 %, Test accuracy: 85.125 %\n",
            "Epoch number: 233 / 1000\n",
            "Cost: 0.55484375, Train accuracy: 85.65625 %, Test accuracy: 86.5625 %\n",
            "Epoch number: 234 / 1000\n",
            "Cost: 0.57671875, Train accuracy: 87.03125 %, Test accuracy: 88.125 %\n",
            "Epoch number: 235 / 1000\n",
            "Cost: 0.5503125, Train accuracy: 85.75 %, Test accuracy: 85.8125 %\n",
            "Epoch number: 236 / 1000\n",
            "Cost: 0.58953125, Train accuracy: 85.515625 %, Test accuracy: 86.1875 %\n",
            "Epoch number: 237 / 1000\n",
            "Cost: 0.5525, Train accuracy: 78.40625 %, Test accuracy: 78.0 %\n",
            "Epoch number: 238 / 1000\n",
            "Cost: 0.65546875, Train accuracy: 74.25 %, Test accuracy: 76.0625 %\n",
            "Epoch number: 239 / 1000\n",
            "Cost: 0.629375, Train accuracy: 77.421875 %, Test accuracy: 77.1875 %\n",
            "Epoch number: 240 / 1000\n",
            "Cost: 0.61890625, Train accuracy: 83.390625 %, Test accuracy: 84.625 %\n",
            "Epoch number: 241 / 1000\n",
            "Cost: 0.559375, Train accuracy: 85.453125 %, Test accuracy: 86.375 %\n",
            "Epoch number: 242 / 1000\n",
            "Cost: 0.575625, Train accuracy: 86.984375 %, Test accuracy: 88.125 %\n",
            "Epoch number: 243 / 1000\n",
            "Cost: 0.5496875, Train accuracy: 85.75 %, Test accuracy: 86.0 %\n",
            "Epoch number: 244 / 1000\n",
            "Cost: 0.58953125, Train accuracy: 85.59375 %, Test accuracy: 86.4375 %\n",
            "Epoch number: 245 / 1000\n",
            "Cost: 0.55265625, Train accuracy: 78.84375 %, Test accuracy: 78.1875 %\n",
            "Epoch number: 246 / 1000\n",
            "Cost: 0.651875, Train accuracy: 74.734375 %, Test accuracy: 76.4375 %\n",
            "Epoch number: 247 / 1000\n",
            "Cost: 0.6253125, Train accuracy: 77.25 %, Test accuracy: 77.125 %\n",
            "Epoch number: 248 / 1000\n",
            "Cost: 0.62203125, Train accuracy: 83.15625 %, Test accuracy: 84.5 %\n",
            "Epoch number: 249 / 1000\n",
            "Cost: 0.5609375, Train accuracy: 85.296875 %, Test accuracy: 86.125 %\n",
            "Epoch number: 250 / 1000\n",
            "Cost: 0.57671875, Train accuracy: 86.890625 %, Test accuracy: 88.125 %\n",
            "Epoch number: 251 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 85.71875 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 252 / 1000\n",
            "Cost: 0.59, Train accuracy: 85.53125 %, Test accuracy: 86.3125 %\n",
            "Epoch number: 253 / 1000\n",
            "Cost: 0.553125, Train accuracy: 78.890625 %, Test accuracy: 78.1875 %\n",
            "Epoch number: 254 / 1000\n",
            "Cost: 0.6509375, Train accuracy: 74.90625 %, Test accuracy: 76.5 %\n",
            "Epoch number: 255 / 1000\n",
            "Cost: 0.62390625, Train accuracy: 77.296875 %, Test accuracy: 77.3125 %\n",
            "Epoch number: 256 / 1000\n",
            "Cost: 0.62203125, Train accuracy: 83.125 %, Test accuracy: 84.3125 %\n",
            "Epoch number: 257 / 1000\n",
            "Cost: 0.56171875, Train accuracy: 85.265625 %, Test accuracy: 86.0 %\n",
            "Epoch number: 258 / 1000\n",
            "Cost: 0.5771875, Train accuracy: 86.765625 %, Test accuracy: 88.0 %\n",
            "Epoch number: 259 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 85.609375 %, Test accuracy: 86.125 %\n",
            "Epoch number: 260 / 1000\n",
            "Cost: 0.59078125, Train accuracy: 85.578125 %, Test accuracy: 86.25 %\n",
            "Epoch number: 261 / 1000\n",
            "Cost: 0.5525, Train accuracy: 78.890625 %, Test accuracy: 78.0625 %\n",
            "Epoch number: 262 / 1000\n",
            "Cost: 0.6515625, Train accuracy: 74.9375 %, Test accuracy: 76.5 %\n",
            "Epoch number: 263 / 1000\n",
            "Cost: 0.62375, Train accuracy: 77.375 %, Test accuracy: 77.375 %\n",
            "Epoch number: 264 / 1000\n",
            "Cost: 0.62171875, Train accuracy: 83.140625 %, Test accuracy: 84.4375 %\n",
            "Epoch number: 265 / 1000\n",
            "Cost: 0.56140625, Train accuracy: 85.28125 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 266 / 1000\n",
            "Cost: 0.576875, Train accuracy: 86.84375 %, Test accuracy: 88.0625 %\n",
            "Epoch number: 267 / 1000\n",
            "Cost: 0.54921875, Train accuracy: 85.5625 %, Test accuracy: 86.0 %\n",
            "Epoch number: 268 / 1000\n",
            "Cost: 0.5915625, Train accuracy: 85.546875 %, Test accuracy: 86.1875 %\n",
            "Epoch number: 269 / 1000\n",
            "Cost: 0.5525, Train accuracy: 78.84375 %, Test accuracy: 78.0625 %\n",
            "Epoch number: 270 / 1000\n",
            "Cost: 0.65140625, Train accuracy: 74.90625 %, Test accuracy: 76.5 %\n",
            "Epoch number: 271 / 1000\n",
            "Cost: 0.62390625, Train accuracy: 77.359375 %, Test accuracy: 77.375 %\n",
            "Epoch number: 272 / 1000\n",
            "Cost: 0.62171875, Train accuracy: 83.171875 %, Test accuracy: 84.4375 %\n",
            "Epoch number: 273 / 1000\n",
            "Cost: 0.56140625, Train accuracy: 85.3125 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 274 / 1000\n",
            "Cost: 0.57671875, Train accuracy: 86.859375 %, Test accuracy: 87.9375 %\n",
            "Epoch number: 275 / 1000\n",
            "Cost: 0.549375, Train accuracy: 85.59375 %, Test accuracy: 86.125 %\n",
            "Epoch number: 276 / 1000\n",
            "Cost: 0.59125, Train accuracy: 85.5625 %, Test accuracy: 86.25 %\n",
            "Epoch number: 277 / 1000\n",
            "Cost: 0.55265625, Train accuracy: 78.921875 %, Test accuracy: 78.1875 %\n",
            "Epoch number: 278 / 1000\n",
            "Cost: 0.650625, Train accuracy: 74.953125 %, Test accuracy: 76.5 %\n",
            "Epoch number: 279 / 1000\n",
            "Cost: 0.62375, Train accuracy: 77.34375 %, Test accuracy: 77.3125 %\n",
            "Epoch number: 280 / 1000\n",
            "Cost: 0.62203125, Train accuracy: 83.140625 %, Test accuracy: 84.3125 %\n",
            "Epoch number: 281 / 1000\n",
            "Cost: 0.56140625, Train accuracy: 85.265625 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 282 / 1000\n",
            "Cost: 0.576875, Train accuracy: 86.828125 %, Test accuracy: 88.0 %\n",
            "Epoch number: 283 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 85.578125 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 284 / 1000\n",
            "Cost: 0.59125, Train accuracy: 85.5625 %, Test accuracy: 86.25 %\n",
            "Epoch number: 285 / 1000\n",
            "Cost: 0.5528125, Train accuracy: 78.828125 %, Test accuracy: 78.1875 %\n",
            "Epoch number: 286 / 1000\n",
            "Cost: 0.65171875, Train accuracy: 74.828125 %, Test accuracy: 76.5 %\n",
            "Epoch number: 287 / 1000\n",
            "Cost: 0.62421875, Train accuracy: 77.421875 %, Test accuracy: 77.375 %\n",
            "Epoch number: 288 / 1000\n",
            "Cost: 0.62109375, Train accuracy: 83.25 %, Test accuracy: 84.5 %\n",
            "Epoch number: 289 / 1000\n",
            "Cost: 0.5609375, Train accuracy: 85.28125 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 290 / 1000\n",
            "Cost: 0.576875, Train accuracy: 86.796875 %, Test accuracy: 87.9375 %\n",
            "Epoch number: 291 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 85.5625 %, Test accuracy: 86.125 %\n",
            "Epoch number: 292 / 1000\n",
            "Cost: 0.59140625, Train accuracy: 85.53125 %, Test accuracy: 86.3125 %\n",
            "Epoch number: 293 / 1000\n",
            "Cost: 0.553125, Train accuracy: 78.796875 %, Test accuracy: 78.1875 %\n",
            "Epoch number: 294 / 1000\n",
            "Cost: 0.6515625, Train accuracy: 74.921875 %, Test accuracy: 76.5 %\n",
            "Epoch number: 295 / 1000\n",
            "Cost: 0.62390625, Train accuracy: 77.375 %, Test accuracy: 77.375 %\n",
            "Epoch number: 296 / 1000\n",
            "Cost: 0.62125, Train accuracy: 83.1875 %, Test accuracy: 84.4375 %\n",
            "Epoch number: 297 / 1000\n",
            "Cost: 0.56109375, Train accuracy: 85.296875 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 298 / 1000\n",
            "Cost: 0.5771875, Train accuracy: 86.75 %, Test accuracy: 88.0 %\n",
            "Epoch number: 299 / 1000\n",
            "Cost: 0.5496875, Train accuracy: 85.53125 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 300 / 1000\n",
            "Cost: 0.59140625, Train accuracy: 85.5625 %, Test accuracy: 86.25 %\n",
            "Epoch number: 301 / 1000\n",
            "Cost: 0.5528125, Train accuracy: 78.953125 %, Test accuracy: 78.1875 %\n",
            "Epoch number: 302 / 1000\n",
            "Cost: 0.65046875, Train accuracy: 75.03125 %, Test accuracy: 76.625 %\n",
            "Epoch number: 303 / 1000\n",
            "Cost: 0.62328125, Train accuracy: 77.328125 %, Test accuracy: 77.3125 %\n",
            "Epoch number: 304 / 1000\n",
            "Cost: 0.6221875, Train accuracy: 82.953125 %, Test accuracy: 84.25 %\n",
            "Epoch number: 305 / 1000\n",
            "Cost: 0.5628125, Train accuracy: 85.203125 %, Test accuracy: 85.75 %\n",
            "Epoch number: 306 / 1000\n",
            "Cost: 0.5778125, Train accuracy: 86.609375 %, Test accuracy: 88.0 %\n",
            "Epoch number: 307 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 85.53125 %, Test accuracy: 85.9375 %\n",
            "Epoch number: 308 / 1000\n",
            "Cost: 0.59125, Train accuracy: 85.625 %, Test accuracy: 86.4375 %\n",
            "Epoch number: 309 / 1000\n",
            "Cost: 0.5525, Train accuracy: 78.984375 %, Test accuracy: 78.125 %\n",
            "Epoch number: 310 / 1000\n",
            "Cost: 0.65046875, Train accuracy: 75.109375 %, Test accuracy: 76.8125 %\n",
            "Epoch number: 311 / 1000\n",
            "Cost: 0.62296875, Train accuracy: 77.3125 %, Test accuracy: 77.3125 %\n",
            "Epoch number: 312 / 1000\n",
            "Cost: 0.62234375, Train accuracy: 82.953125 %, Test accuracy: 84.1875 %\n",
            "Epoch number: 313 / 1000\n",
            "Cost: 0.56265625, Train accuracy: 85.203125 %, Test accuracy: 85.75 %\n",
            "Epoch number: 314 / 1000\n",
            "Cost: 0.5778125, Train accuracy: 86.609375 %, Test accuracy: 88.0 %\n",
            "Epoch number: 315 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 85.5 %, Test accuracy: 86.0 %\n",
            "Epoch number: 316 / 1000\n",
            "Cost: 0.5915625, Train accuracy: 85.546875 %, Test accuracy: 86.3125 %\n",
            "Epoch number: 317 / 1000\n",
            "Cost: 0.55296875, Train accuracy: 78.9375 %, Test accuracy: 78.1875 %\n",
            "Epoch number: 318 / 1000\n",
            "Cost: 0.65078125, Train accuracy: 75.0625 %, Test accuracy: 76.75 %\n",
            "Epoch number: 319 / 1000\n",
            "Cost: 0.62296875, Train accuracy: 77.390625 %, Test accuracy: 77.375 %\n",
            "Epoch number: 320 / 1000\n",
            "Cost: 0.62171875, Train accuracy: 83.03125 %, Test accuracy: 84.3125 %\n",
            "Epoch number: 321 / 1000\n",
            "Cost: 0.5625, Train accuracy: 85.234375 %, Test accuracy: 85.75 %\n",
            "Epoch number: 322 / 1000\n",
            "Cost: 0.57734375, Train accuracy: 86.734375 %, Test accuracy: 88.0625 %\n",
            "Epoch number: 323 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 85.5625 %, Test accuracy: 85.875 %\n",
            "Epoch number: 324 / 1000\n",
            "Cost: 0.59109375, Train accuracy: 85.578125 %, Test accuracy: 86.1875 %\n",
            "Epoch number: 325 / 1000\n",
            "Cost: 0.5525, Train accuracy: 78.84375 %, Test accuracy: 78.0625 %\n",
            "Epoch number: 326 / 1000\n",
            "Cost: 0.65171875, Train accuracy: 74.921875 %, Test accuracy: 76.5 %\n",
            "Epoch number: 327 / 1000\n",
            "Cost: 0.62375, Train accuracy: 77.515625 %, Test accuracy: 77.4375 %\n",
            "Epoch number: 328 / 1000\n",
            "Cost: 0.62046875, Train accuracy: 83.21875 %, Test accuracy: 84.5625 %\n",
            "Epoch number: 329 / 1000\n",
            "Cost: 0.5609375, Train accuracy: 85.28125 %, Test accuracy: 85.8125 %\n",
            "Epoch number: 330 / 1000\n",
            "Cost: 0.5778125, Train accuracy: 86.671875 %, Test accuracy: 88.0 %\n",
            "Epoch number: 331 / 1000\n",
            "Cost: 0.549375, Train accuracy: 85.4375 %, Test accuracy: 86.0 %\n",
            "Epoch number: 332 / 1000\n",
            "Cost: 0.5925, Train accuracy: 85.53125 %, Test accuracy: 86.1875 %\n",
            "Epoch number: 333 / 1000\n",
            "Cost: 0.5525, Train accuracy: 78.90625 %, Test accuracy: 78.0 %\n",
            "Epoch number: 334 / 1000\n",
            "Cost: 0.65125, Train accuracy: 74.984375 %, Test accuracy: 76.6875 %\n",
            "Epoch number: 335 / 1000\n",
            "Cost: 0.6234375, Train accuracy: 77.40625 %, Test accuracy: 77.375 %\n",
            "Epoch number: 336 / 1000\n",
            "Cost: 0.6215625, Train accuracy: 83.140625 %, Test accuracy: 84.375 %\n",
            "Epoch number: 337 / 1000\n",
            "Cost: 0.56140625, Train accuracy: 85.28125 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 338 / 1000\n",
            "Cost: 0.57703125, Train accuracy: 86.84375 %, Test accuracy: 88.0 %\n",
            "Epoch number: 339 / 1000\n",
            "Cost: 0.54921875, Train accuracy: 85.546875 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 340 / 1000\n",
            "Cost: 0.59140625, Train accuracy: 85.5625 %, Test accuracy: 86.25 %\n",
            "Epoch number: 341 / 1000\n",
            "Cost: 0.55265625, Train accuracy: 78.859375 %, Test accuracy: 78.125 %\n",
            "Epoch number: 342 / 1000\n",
            "Cost: 0.6515625, Train accuracy: 74.84375 %, Test accuracy: 76.5 %\n",
            "Epoch number: 343 / 1000\n",
            "Cost: 0.6246875, Train accuracy: 77.296875 %, Test accuracy: 77.375 %\n",
            "Epoch number: 344 / 1000\n",
            "Cost: 0.621875, Train accuracy: 83.171875 %, Test accuracy: 84.4375 %\n",
            "Epoch number: 345 / 1000\n",
            "Cost: 0.56109375, Train accuracy: 85.296875 %, Test accuracy: 86.0 %\n",
            "Epoch number: 346 / 1000\n",
            "Cost: 0.57671875, Train accuracy: 86.90625 %, Test accuracy: 88.125 %\n",
            "Epoch number: 347 / 1000\n",
            "Cost: 0.54921875, Train accuracy: 85.703125 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 348 / 1000\n",
            "Cost: 0.5903125, Train accuracy: 85.546875 %, Test accuracy: 86.25 %\n",
            "Epoch number: 349 / 1000\n",
            "Cost: 0.55296875, Train accuracy: 78.875 %, Test accuracy: 78.125 %\n",
            "Epoch number: 350 / 1000\n",
            "Cost: 0.65125, Train accuracy: 74.875 %, Test accuracy: 76.5 %\n",
            "Epoch number: 351 / 1000\n",
            "Cost: 0.6240625, Train accuracy: 77.359375 %, Test accuracy: 77.375 %\n",
            "Epoch number: 352 / 1000\n",
            "Cost: 0.62140625, Train accuracy: 83.171875 %, Test accuracy: 84.375 %\n",
            "Epoch number: 353 / 1000\n",
            "Cost: 0.56140625, Train accuracy: 85.28125 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 354 / 1000\n",
            "Cost: 0.57703125, Train accuracy: 86.8125 %, Test accuracy: 87.9375 %\n",
            "Epoch number: 355 / 1000\n",
            "Cost: 0.54921875, Train accuracy: 85.515625 %, Test accuracy: 86.0 %\n",
            "Epoch number: 356 / 1000\n",
            "Cost: 0.59171875, Train accuracy: 85.5625 %, Test accuracy: 86.25 %\n",
            "Epoch number: 357 / 1000\n",
            "Cost: 0.55265625, Train accuracy: 78.9375 %, Test accuracy: 78.125 %\n",
            "Epoch number: 358 / 1000\n",
            "Cost: 0.650625, Train accuracy: 75.03125 %, Test accuracy: 76.5625 %\n",
            "Epoch number: 359 / 1000\n",
            "Cost: 0.6234375, Train accuracy: 77.328125 %, Test accuracy: 77.3125 %\n",
            "Epoch number: 360 / 1000\n",
            "Cost: 0.6221875, Train accuracy: 82.984375 %, Test accuracy: 84.25 %\n",
            "Epoch number: 361 / 1000\n",
            "Cost: 0.5625, Train accuracy: 85.234375 %, Test accuracy: 85.75 %\n",
            "Epoch number: 362 / 1000\n",
            "Cost: 0.5775, Train accuracy: 86.78125 %, Test accuracy: 88.0 %\n",
            "Epoch number: 363 / 1000\n",
            "Cost: 0.549375, Train accuracy: 85.59375 %, Test accuracy: 85.9375 %\n",
            "Epoch number: 364 / 1000\n",
            "Cost: 0.59078125, Train accuracy: 85.546875 %, Test accuracy: 86.4375 %\n",
            "Epoch number: 365 / 1000\n",
            "Cost: 0.55265625, Train accuracy: 78.921875 %, Test accuracy: 78.125 %\n",
            "Epoch number: 366 / 1000\n",
            "Cost: 0.65109375, Train accuracy: 75.015625 %, Test accuracy: 76.5625 %\n",
            "Epoch number: 367 / 1000\n",
            "Cost: 0.62328125, Train accuracy: 77.40625 %, Test accuracy: 77.375 %\n",
            "Epoch number: 368 / 1000\n",
            "Cost: 0.62140625, Train accuracy: 83.125 %, Test accuracy: 84.3125 %\n",
            "Epoch number: 369 / 1000\n",
            "Cost: 0.56171875, Train accuracy: 85.265625 %, Test accuracy: 85.875 %\n",
            "Epoch number: 370 / 1000\n",
            "Cost: 0.5771875, Train accuracy: 86.75 %, Test accuracy: 87.9375 %\n",
            "Epoch number: 371 / 1000\n",
            "Cost: 0.549375, Train accuracy: 85.515625 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 372 / 1000\n",
            "Cost: 0.59171875, Train accuracy: 85.546875 %, Test accuracy: 86.1875 %\n",
            "Epoch number: 373 / 1000\n",
            "Cost: 0.55234375, Train accuracy: 78.734375 %, Test accuracy: 78.1875 %\n",
            "Epoch number: 374 / 1000\n",
            "Cost: 0.6525, Train accuracy: 74.8125 %, Test accuracy: 76.5 %\n",
            "Epoch number: 375 / 1000\n",
            "Cost: 0.62453125, Train accuracy: 77.53125 %, Test accuracy: 77.4375 %\n",
            "Epoch number: 376 / 1000\n",
            "Cost: 0.62046875, Train accuracy: 83.28125 %, Test accuracy: 84.5 %\n",
            "Epoch number: 377 / 1000\n",
            "Cost: 0.5603125, Train accuracy: 85.375 %, Test accuracy: 86.125 %\n",
            "Epoch number: 378 / 1000\n",
            "Cost: 0.576875, Train accuracy: 86.890625 %, Test accuracy: 88.125 %\n",
            "Epoch number: 379 / 1000\n",
            "Cost: 0.5496875, Train accuracy: 85.671875 %, Test accuracy: 86.1875 %\n",
            "Epoch number: 380 / 1000\n",
            "Cost: 0.59046875, Train accuracy: 85.515625 %, Test accuracy: 86.25 %\n",
            "Epoch number: 381 / 1000\n",
            "Cost: 0.55296875, Train accuracy: 78.796875 %, Test accuracy: 78.125 %\n",
            "Epoch number: 382 / 1000\n",
            "Cost: 0.651875, Train accuracy: 74.75 %, Test accuracy: 76.4375 %\n",
            "Epoch number: 383 / 1000\n",
            "Cost: 0.62484375, Train accuracy: 77.359375 %, Test accuracy: 77.375 %\n",
            "Epoch number: 384 / 1000\n",
            "Cost: 0.62140625, Train accuracy: 83.203125 %, Test accuracy: 84.5625 %\n",
            "Epoch number: 385 / 1000\n",
            "Cost: 0.56078125, Train accuracy: 85.28125 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 386 / 1000\n",
            "Cost: 0.57703125, Train accuracy: 86.828125 %, Test accuracy: 87.9375 %\n",
            "Epoch number: 387 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 85.578125 %, Test accuracy: 86.125 %\n",
            "Epoch number: 388 / 1000\n",
            "Cost: 0.59140625, Train accuracy: 85.5625 %, Test accuracy: 86.25 %\n",
            "Epoch number: 389 / 1000\n",
            "Cost: 0.55265625, Train accuracy: 78.921875 %, Test accuracy: 78.1875 %\n",
            "Epoch number: 390 / 1000\n",
            "Cost: 0.6503125, Train accuracy: 75.0625 %, Test accuracy: 76.6875 %\n",
            "Epoch number: 391 / 1000\n",
            "Cost: 0.62328125, Train accuracy: 77.328125 %, Test accuracy: 77.3125 %\n",
            "Epoch number: 392 / 1000\n",
            "Cost: 0.62203125, Train accuracy: 82.984375 %, Test accuracy: 84.25 %\n",
            "Epoch number: 393 / 1000\n",
            "Cost: 0.5625, Train accuracy: 85.21875 %, Test accuracy: 85.75 %\n",
            "Epoch number: 394 / 1000\n",
            "Cost: 0.57796875, Train accuracy: 86.6875 %, Test accuracy: 88.0625 %\n",
            "Epoch number: 395 / 1000\n",
            "Cost: 0.549375, Train accuracy: 85.53125 %, Test accuracy: 85.875 %\n",
            "Epoch number: 396 / 1000\n",
            "Cost: 0.59125, Train accuracy: 85.5625 %, Test accuracy: 86.4375 %\n",
            "Epoch number: 397 / 1000\n",
            "Cost: 0.5525, Train accuracy: 78.953125 %, Test accuracy: 78.0625 %\n",
            "Epoch number: 398 / 1000\n",
            "Cost: 0.65109375, Train accuracy: 75.015625 %, Test accuracy: 76.75 %\n",
            "Epoch number: 399 / 1000\n",
            "Cost: 0.623125, Train accuracy: 77.328125 %, Test accuracy: 77.375 %\n",
            "Epoch number: 400 / 1000\n",
            "Cost: 0.6221875, Train accuracy: 83.046875 %, Test accuracy: 84.3125 %\n",
            "Epoch number: 401 / 1000\n",
            "Cost: 0.5625, Train accuracy: 85.28125 %, Test accuracy: 85.8125 %\n",
            "Epoch number: 402 / 1000\n",
            "Cost: 0.576875, Train accuracy: 86.734375 %, Test accuracy: 88.0625 %\n",
            "Epoch number: 403 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 85.5625 %, Test accuracy: 86.0 %\n",
            "Epoch number: 404 / 1000\n",
            "Cost: 0.5909375, Train accuracy: 85.546875 %, Test accuracy: 86.3125 %\n",
            "Epoch number: 405 / 1000\n",
            "Cost: 0.55296875, Train accuracy: 78.875 %, Test accuracy: 78.125 %\n",
            "Epoch number: 406 / 1000\n",
            "Cost: 0.65125, Train accuracy: 74.953125 %, Test accuracy: 76.5 %\n",
            "Epoch number: 407 / 1000\n",
            "Cost: 0.62375, Train accuracy: 77.40625 %, Test accuracy: 77.375 %\n",
            "Epoch number: 408 / 1000\n",
            "Cost: 0.62140625, Train accuracy: 83.15625 %, Test accuracy: 84.4375 %\n",
            "Epoch number: 409 / 1000\n",
            "Cost: 0.56140625, Train accuracy: 85.25 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 410 / 1000\n",
            "Cost: 0.57703125, Train accuracy: 86.828125 %, Test accuracy: 87.9375 %\n",
            "Epoch number: 411 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 85.5625 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 412 / 1000\n",
            "Cost: 0.59125, Train accuracy: 85.515625 %, Test accuracy: 86.25 %\n",
            "Epoch number: 413 / 1000\n",
            "Cost: 0.553125, Train accuracy: 78.890625 %, Test accuracy: 78.25 %\n",
            "Epoch number: 414 / 1000\n",
            "Cost: 0.6509375, Train accuracy: 74.9375 %, Test accuracy: 76.5 %\n",
            "Epoch number: 415 / 1000\n",
            "Cost: 0.62375, Train accuracy: 77.328125 %, Test accuracy: 77.3125 %\n",
            "Epoch number: 416 / 1000\n",
            "Cost: 0.621875, Train accuracy: 83.125 %, Test accuracy: 84.3125 %\n",
            "Epoch number: 417 / 1000\n",
            "Cost: 0.5615625, Train accuracy: 85.265625 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 418 / 1000\n",
            "Cost: 0.576875, Train accuracy: 86.890625 %, Test accuracy: 88.0625 %\n",
            "Epoch number: 419 / 1000\n",
            "Cost: 0.549375, Train accuracy: 85.65625 %, Test accuracy: 86.1875 %\n",
            "Epoch number: 420 / 1000\n",
            "Cost: 0.59078125, Train accuracy: 85.546875 %, Test accuracy: 86.3125 %\n",
            "Epoch number: 421 / 1000\n",
            "Cost: 0.55328125, Train accuracy: 78.796875 %, Test accuracy: 78.1875 %\n",
            "Epoch number: 422 / 1000\n",
            "Cost: 0.65109375, Train accuracy: 74.875 %, Test accuracy: 76.5625 %\n",
            "Epoch number: 423 / 1000\n",
            "Cost: 0.6240625, Train accuracy: 77.296875 %, Test accuracy: 77.375 %\n",
            "Epoch number: 424 / 1000\n",
            "Cost: 0.62203125, Train accuracy: 83.15625 %, Test accuracy: 84.3125 %\n",
            "Epoch number: 425 / 1000\n",
            "Cost: 0.56140625, Train accuracy: 85.296875 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 426 / 1000\n",
            "Cost: 0.57671875, Train accuracy: 86.875 %, Test accuracy: 88.125 %\n",
            "Epoch number: 427 / 1000\n",
            "Cost: 0.54921875, Train accuracy: 85.625 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 428 / 1000\n",
            "Cost: 0.59109375, Train accuracy: 85.53125 %, Test accuracy: 86.25 %\n",
            "Epoch number: 429 / 1000\n",
            "Cost: 0.55296875, Train accuracy: 78.90625 %, Test accuracy: 78.125 %\n",
            "Epoch number: 430 / 1000\n",
            "Cost: 0.6509375, Train accuracy: 74.890625 %, Test accuracy: 76.5 %\n",
            "Epoch number: 431 / 1000\n",
            "Cost: 0.62390625, Train accuracy: 77.3125 %, Test accuracy: 77.375 %\n",
            "Epoch number: 432 / 1000\n",
            "Cost: 0.62203125, Train accuracy: 83.109375 %, Test accuracy: 84.375 %\n",
            "Epoch number: 433 / 1000\n",
            "Cost: 0.5615625, Train accuracy: 85.28125 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 434 / 1000\n",
            "Cost: 0.576875, Train accuracy: 86.859375 %, Test accuracy: 88.0625 %\n",
            "Epoch number: 435 / 1000\n",
            "Cost: 0.549375, Train accuracy: 85.59375 %, Test accuracy: 86.125 %\n",
            "Epoch number: 436 / 1000\n",
            "Cost: 0.59109375, Train accuracy: 85.546875 %, Test accuracy: 86.25 %\n",
            "Epoch number: 437 / 1000\n",
            "Cost: 0.55265625, Train accuracy: 78.875 %, Test accuracy: 78.125 %\n",
            "Epoch number: 438 / 1000\n",
            "Cost: 0.65125, Train accuracy: 74.828125 %, Test accuracy: 76.5 %\n",
            "Epoch number: 439 / 1000\n",
            "Cost: 0.6246875, Train accuracy: 77.359375 %, Test accuracy: 77.375 %\n",
            "Epoch number: 440 / 1000\n",
            "Cost: 0.6215625, Train accuracy: 83.21875 %, Test accuracy: 84.5625 %\n",
            "Epoch number: 441 / 1000\n",
            "Cost: 0.5609375, Train accuracy: 85.296875 %, Test accuracy: 86.125 %\n",
            "Epoch number: 442 / 1000\n",
            "Cost: 0.57671875, Train accuracy: 86.859375 %, Test accuracy: 88.0 %\n",
            "Epoch number: 443 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 85.625 %, Test accuracy: 86.125 %\n",
            "Epoch number: 444 / 1000\n",
            "Cost: 0.5909375, Train accuracy: 85.5625 %, Test accuracy: 86.3125 %\n",
            "Epoch number: 445 / 1000\n",
            "Cost: 0.553125, Train accuracy: 78.890625 %, Test accuracy: 78.1875 %\n",
            "Epoch number: 446 / 1000\n",
            "Cost: 0.65046875, Train accuracy: 74.96875 %, Test accuracy: 76.75 %\n",
            "Epoch number: 447 / 1000\n",
            "Cost: 0.62359375, Train accuracy: 77.234375 %, Test accuracy: 77.25 %\n",
            "Epoch number: 448 / 1000\n",
            "Cost: 0.62265625, Train accuracy: 83.0 %, Test accuracy: 84.25 %\n",
            "Epoch number: 449 / 1000\n",
            "Cost: 0.56265625, Train accuracy: 85.265625 %, Test accuracy: 85.9375 %\n",
            "Epoch number: 450 / 1000\n",
            "Cost: 0.576875, Train accuracy: 86.8125 %, Test accuracy: 88.125 %\n",
            "Epoch number: 451 / 1000\n",
            "Cost: 0.549375, Train accuracy: 85.625 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 452 / 1000\n",
            "Cost: 0.59046875, Train accuracy: 85.53125 %, Test accuracy: 86.4375 %\n",
            "Epoch number: 453 / 1000\n",
            "Cost: 0.5528125, Train accuracy: 78.9375 %, Test accuracy: 78.0625 %\n",
            "Epoch number: 454 / 1000\n",
            "Cost: 0.6509375, Train accuracy: 75.03125 %, Test accuracy: 76.625 %\n",
            "Epoch number: 455 / 1000\n",
            "Cost: 0.62328125, Train accuracy: 77.390625 %, Test accuracy: 77.375 %\n",
            "Epoch number: 456 / 1000\n",
            "Cost: 0.6215625, Train accuracy: 83.046875 %, Test accuracy: 84.375 %\n",
            "Epoch number: 457 / 1000\n",
            "Cost: 0.56234375, Train accuracy: 85.265625 %, Test accuracy: 85.75 %\n",
            "Epoch number: 458 / 1000\n",
            "Cost: 0.5771875, Train accuracy: 86.703125 %, Test accuracy: 88.0625 %\n",
            "Epoch number: 459 / 1000\n",
            "Cost: 0.5496875, Train accuracy: 85.546875 %, Test accuracy: 86.0 %\n",
            "Epoch number: 460 / 1000\n",
            "Cost: 0.59125, Train accuracy: 85.578125 %, Test accuracy: 86.3125 %\n",
            "Epoch number: 461 / 1000\n",
            "Cost: 0.5525, Train accuracy: 78.9375 %, Test accuracy: 78.125 %\n",
            "Epoch number: 462 / 1000\n",
            "Cost: 0.65078125, Train accuracy: 75.0 %, Test accuracy: 76.6875 %\n",
            "Epoch number: 463 / 1000\n",
            "Cost: 0.6234375, Train accuracy: 77.296875 %, Test accuracy: 77.3125 %\n",
            "Epoch number: 464 / 1000\n",
            "Cost: 0.62234375, Train accuracy: 83.015625 %, Test accuracy: 84.375 %\n",
            "Epoch number: 465 / 1000\n",
            "Cost: 0.5625, Train accuracy: 85.234375 %, Test accuracy: 85.875 %\n",
            "Epoch number: 466 / 1000\n",
            "Cost: 0.57734375, Train accuracy: 86.78125 %, Test accuracy: 88.0 %\n",
            "Epoch number: 467 / 1000\n",
            "Cost: 0.549375, Train accuracy: 85.546875 %, Test accuracy: 85.9375 %\n",
            "Epoch number: 468 / 1000\n",
            "Cost: 0.59125, Train accuracy: 85.5625 %, Test accuracy: 86.4375 %\n",
            "Epoch number: 469 / 1000\n",
            "Cost: 0.5525, Train accuracy: 78.921875 %, Test accuracy: 78.0625 %\n",
            "Epoch number: 470 / 1000\n",
            "Cost: 0.65078125, Train accuracy: 75.03125 %, Test accuracy: 76.8125 %\n",
            "Epoch number: 471 / 1000\n",
            "Cost: 0.623125, Train accuracy: 77.328125 %, Test accuracy: 77.3125 %\n",
            "Epoch number: 472 / 1000\n",
            "Cost: 0.62234375, Train accuracy: 83.0 %, Test accuracy: 84.25 %\n",
            "Epoch number: 473 / 1000\n",
            "Cost: 0.5625, Train accuracy: 85.296875 %, Test accuracy: 85.875 %\n",
            "Epoch number: 474 / 1000\n",
            "Cost: 0.576875, Train accuracy: 86.75 %, Test accuracy: 88.125 %\n",
            "Epoch number: 475 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 85.578125 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 476 / 1000\n",
            "Cost: 0.5909375, Train accuracy: 85.578125 %, Test accuracy: 86.25 %\n",
            "Epoch number: 477 / 1000\n",
            "Cost: 0.5525, Train accuracy: 78.9375 %, Test accuracy: 78.0625 %\n",
            "Epoch number: 478 / 1000\n",
            "Cost: 0.6509375, Train accuracy: 74.984375 %, Test accuracy: 76.6875 %\n",
            "Epoch number: 479 / 1000\n",
            "Cost: 0.6234375, Train accuracy: 77.328125 %, Test accuracy: 77.3125 %\n",
            "Epoch number: 480 / 1000\n",
            "Cost: 0.6221875, Train accuracy: 83.0625 %, Test accuracy: 84.3125 %\n",
            "Epoch number: 481 / 1000\n",
            "Cost: 0.5621875, Train accuracy: 85.234375 %, Test accuracy: 85.875 %\n",
            "Epoch number: 482 / 1000\n",
            "Cost: 0.57703125, Train accuracy: 86.8125 %, Test accuracy: 88.125 %\n",
            "Epoch number: 483 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 85.625 %, Test accuracy: 86.125 %\n",
            "Epoch number: 484 / 1000\n",
            "Cost: 0.590625, Train accuracy: 85.515625 %, Test accuracy: 86.25 %\n",
            "Epoch number: 485 / 1000\n",
            "Cost: 0.55296875, Train accuracy: 78.859375 %, Test accuracy: 78.1875 %\n",
            "Epoch number: 486 / 1000\n",
            "Cost: 0.6515625, Train accuracy: 74.90625 %, Test accuracy: 76.5 %\n",
            "Epoch number: 487 / 1000\n",
            "Cost: 0.62390625, Train accuracy: 77.375 %, Test accuracy: 77.375 %\n",
            "Epoch number: 488 / 1000\n",
            "Cost: 0.62140625, Train accuracy: 83.15625 %, Test accuracy: 84.4375 %\n",
            "Epoch number: 489 / 1000\n",
            "Cost: 0.56140625, Train accuracy: 85.28125 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 490 / 1000\n",
            "Cost: 0.576875, Train accuracy: 86.8125 %, Test accuracy: 87.9375 %\n",
            "Epoch number: 491 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 85.5625 %, Test accuracy: 86.125 %\n",
            "Epoch number: 492 / 1000\n",
            "Cost: 0.5915625, Train accuracy: 85.5625 %, Test accuracy: 86.25 %\n",
            "Epoch number: 493 / 1000\n",
            "Cost: 0.55265625, Train accuracy: 78.890625 %, Test accuracy: 78.1875 %\n",
            "Epoch number: 494 / 1000\n",
            "Cost: 0.650625, Train accuracy: 74.953125 %, Test accuracy: 76.5 %\n",
            "Epoch number: 495 / 1000\n",
            "Cost: 0.62375, Train accuracy: 77.3125 %, Test accuracy: 77.25 %\n",
            "Epoch number: 496 / 1000\n",
            "Cost: 0.62234375, Train accuracy: 83.09375 %, Test accuracy: 84.25 %\n",
            "Epoch number: 497 / 1000\n",
            "Cost: 0.56171875, Train accuracy: 85.28125 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 498 / 1000\n",
            "Cost: 0.57671875, Train accuracy: 86.84375 %, Test accuracy: 88.0625 %\n",
            "Epoch number: 499 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 85.59375 %, Test accuracy: 86.125 %\n",
            "Epoch number: 500 / 1000\n",
            "Cost: 0.59109375, Train accuracy: 85.546875 %, Test accuracy: 86.25 %\n",
            "Epoch number: 501 / 1000\n",
            "Cost: 0.55296875, Train accuracy: 78.90625 %, Test accuracy: 78.1875 %\n",
            "Epoch number: 502 / 1000\n",
            "Cost: 0.650625, Train accuracy: 74.953125 %, Test accuracy: 76.625 %\n",
            "Epoch number: 503 / 1000\n",
            "Cost: 0.62359375, Train accuracy: 77.3125 %, Test accuracy: 77.25 %\n",
            "Epoch number: 504 / 1000\n",
            "Cost: 0.62234375, Train accuracy: 83.09375 %, Test accuracy: 84.3125 %\n",
            "Epoch number: 505 / 1000\n",
            "Cost: 0.56203125, Train accuracy: 85.28125 %, Test accuracy: 86.0 %\n",
            "Epoch number: 506 / 1000\n",
            "Cost: 0.5765625, Train accuracy: 86.859375 %, Test accuracy: 88.0625 %\n",
            "Epoch number: 507 / 1000\n",
            "Cost: 0.549375, Train accuracy: 85.625 %, Test accuracy: 86.1875 %\n",
            "Epoch number: 508 / 1000\n",
            "Cost: 0.59109375, Train accuracy: 85.515625 %, Test accuracy: 86.25 %\n",
            "Epoch number: 509 / 1000\n",
            "Cost: 0.55296875, Train accuracy: 78.8125 %, Test accuracy: 78.125 %\n",
            "Epoch number: 510 / 1000\n",
            "Cost: 0.65140625, Train accuracy: 74.890625 %, Test accuracy: 76.5 %\n",
            "Epoch number: 511 / 1000\n",
            "Cost: 0.6240625, Train accuracy: 77.375 %, Test accuracy: 77.375 %\n",
            "Epoch number: 512 / 1000\n",
            "Cost: 0.62140625, Train accuracy: 83.171875 %, Test accuracy: 84.4375 %\n",
            "Epoch number: 513 / 1000\n",
            "Cost: 0.56125, Train accuracy: 85.265625 %, Test accuracy: 86.0 %\n",
            "Epoch number: 514 / 1000\n",
            "Cost: 0.5771875, Train accuracy: 86.8125 %, Test accuracy: 87.9375 %\n",
            "Epoch number: 515 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 85.59375 %, Test accuracy: 86.125 %\n",
            "Epoch number: 516 / 1000\n",
            "Cost: 0.59109375, Train accuracy: 85.53125 %, Test accuracy: 86.25 %\n",
            "Epoch number: 517 / 1000\n",
            "Cost: 0.553125, Train accuracy: 78.875 %, Test accuracy: 78.1875 %\n",
            "Epoch number: 518 / 1000\n",
            "Cost: 0.650625, Train accuracy: 74.953125 %, Test accuracy: 76.5625 %\n",
            "Epoch number: 519 / 1000\n",
            "Cost: 0.62375, Train accuracy: 77.3125 %, Test accuracy: 77.25 %\n",
            "Epoch number: 520 / 1000\n",
            "Cost: 0.62234375, Train accuracy: 83.125 %, Test accuracy: 84.3125 %\n",
            "Epoch number: 521 / 1000\n",
            "Cost: 0.5615625, Train accuracy: 85.28125 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 522 / 1000\n",
            "Cost: 0.57671875, Train accuracy: 86.8125 %, Test accuracy: 87.9375 %\n",
            "Epoch number: 523 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 85.53125 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 524 / 1000\n",
            "Cost: 0.5915625, Train accuracy: 85.546875 %, Test accuracy: 86.1875 %\n",
            "Epoch number: 525 / 1000\n",
            "Cost: 0.55234375, Train accuracy: 78.875 %, Test accuracy: 78.0625 %\n",
            "Epoch number: 526 / 1000\n",
            "Cost: 0.65125, Train accuracy: 74.921875 %, Test accuracy: 76.5625 %\n",
            "Epoch number: 527 / 1000\n",
            "Cost: 0.62375, Train accuracy: 77.328125 %, Test accuracy: 77.3125 %\n",
            "Epoch number: 528 / 1000\n",
            "Cost: 0.6221875, Train accuracy: 83.140625 %, Test accuracy: 84.3125 %\n",
            "Epoch number: 529 / 1000\n",
            "Cost: 0.5615625, Train accuracy: 85.28125 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 530 / 1000\n",
            "Cost: 0.57671875, Train accuracy: 86.84375 %, Test accuracy: 88.0625 %\n",
            "Epoch number: 531 / 1000\n",
            "Cost: 0.549375, Train accuracy: 85.609375 %, Test accuracy: 86.125 %\n",
            "Epoch number: 532 / 1000\n",
            "Cost: 0.59125, Train accuracy: 85.53125 %, Test accuracy: 86.375 %\n",
            "Epoch number: 533 / 1000\n",
            "Cost: 0.55296875, Train accuracy: 78.921875 %, Test accuracy: 78.1875 %\n",
            "Epoch number: 534 / 1000\n",
            "Cost: 0.65046875, Train accuracy: 75.0 %, Test accuracy: 76.75 %\n",
            "Epoch number: 535 / 1000\n",
            "Cost: 0.62328125, Train accuracy: 77.25 %, Test accuracy: 77.3125 %\n",
            "Epoch number: 536 / 1000\n",
            "Cost: 0.62265625, Train accuracy: 82.96875 %, Test accuracy: 84.25 %\n",
            "Epoch number: 537 / 1000\n",
            "Cost: 0.563125, Train accuracy: 85.234375 %, Test accuracy: 85.8125 %\n",
            "Epoch number: 538 / 1000\n",
            "Cost: 0.5771875, Train accuracy: 86.78125 %, Test accuracy: 88.0625 %\n",
            "Epoch number: 539 / 1000\n",
            "Cost: 0.54921875, Train accuracy: 85.609375 %, Test accuracy: 85.9375 %\n",
            "Epoch number: 540 / 1000\n",
            "Cost: 0.590625, Train accuracy: 85.609375 %, Test accuracy: 86.4375 %\n",
            "Epoch number: 541 / 1000\n",
            "Cost: 0.5525, Train accuracy: 78.96875 %, Test accuracy: 78.125 %\n",
            "Epoch number: 542 / 1000\n",
            "Cost: 0.650625, Train accuracy: 75.03125 %, Test accuracy: 76.625 %\n",
            "Epoch number: 543 / 1000\n",
            "Cost: 0.62328125, Train accuracy: 77.328125 %, Test accuracy: 77.3125 %\n",
            "Epoch number: 544 / 1000\n",
            "Cost: 0.6221875, Train accuracy: 83.0 %, Test accuracy: 84.25 %\n",
            "Epoch number: 545 / 1000\n",
            "Cost: 0.5625, Train accuracy: 85.234375 %, Test accuracy: 85.75 %\n",
            "Epoch number: 546 / 1000\n",
            "Cost: 0.57734375, Train accuracy: 86.78125 %, Test accuracy: 88.0 %\n",
            "Epoch number: 547 / 1000\n",
            "Cost: 0.549375, Train accuracy: 85.609375 %, Test accuracy: 85.875 %\n",
            "Epoch number: 548 / 1000\n",
            "Cost: 0.590625, Train accuracy: 85.59375 %, Test accuracy: 86.3125 %\n",
            "Epoch number: 549 / 1000\n",
            "Cost: 0.55265625, Train accuracy: 78.875 %, Test accuracy: 78.0625 %\n",
            "Epoch number: 550 / 1000\n",
            "Cost: 0.65109375, Train accuracy: 74.875 %, Test accuracy: 76.5 %\n",
            "Epoch number: 551 / 1000\n",
            "Cost: 0.62453125, Train accuracy: 77.296875 %, Test accuracy: 77.375 %\n",
            "Epoch number: 552 / 1000\n",
            "Cost: 0.62203125, Train accuracy: 83.1875 %, Test accuracy: 84.4375 %\n",
            "Epoch number: 553 / 1000\n",
            "Cost: 0.5609375, Train accuracy: 85.28125 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 554 / 1000\n",
            "Cost: 0.57671875, Train accuracy: 86.90625 %, Test accuracy: 88.0625 %\n",
            "Epoch number: 555 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 85.703125 %, Test accuracy: 86.125 %\n",
            "Epoch number: 556 / 1000\n",
            "Cost: 0.5903125, Train accuracy: 85.53125 %, Test accuracy: 86.25 %\n",
            "Epoch number: 557 / 1000\n",
            "Cost: 0.553125, Train accuracy: 78.921875 %, Test accuracy: 78.1875 %\n",
            "Epoch number: 558 / 1000\n",
            "Cost: 0.650625, Train accuracy: 74.921875 %, Test accuracy: 76.5625 %\n",
            "Epoch number: 559 / 1000\n",
            "Cost: 0.62375, Train accuracy: 77.28125 %, Test accuracy: 77.25 %\n",
            "Epoch number: 560 / 1000\n",
            "Cost: 0.62234375, Train accuracy: 83.09375 %, Test accuracy: 84.3125 %\n",
            "Epoch number: 561 / 1000\n",
            "Cost: 0.56203125, Train accuracy: 85.265625 %, Test accuracy: 86.0 %\n",
            "Epoch number: 562 / 1000\n",
            "Cost: 0.57671875, Train accuracy: 86.859375 %, Test accuracy: 88.125 %\n",
            "Epoch number: 563 / 1000\n",
            "Cost: 0.5490625, Train accuracy: 85.578125 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 564 / 1000\n",
            "Cost: 0.59140625, Train accuracy: 85.578125 %, Test accuracy: 86.3125 %\n",
            "Epoch number: 565 / 1000\n",
            "Cost: 0.5525, Train accuracy: 78.96875 %, Test accuracy: 78.0625 %\n",
            "Epoch number: 566 / 1000\n",
            "Cost: 0.65046875, Train accuracy: 75.015625 %, Test accuracy: 76.625 %\n",
            "Epoch number: 567 / 1000\n",
            "Cost: 0.6234375, Train accuracy: 77.28125 %, Test accuracy: 77.3125 %\n",
            "Epoch number: 568 / 1000\n",
            "Cost: 0.62234375, Train accuracy: 83.0 %, Test accuracy: 84.25 %\n",
            "Epoch number: 569 / 1000\n",
            "Cost: 0.56265625, Train accuracy: 85.21875 %, Test accuracy: 85.8125 %\n",
            "Epoch number: 570 / 1000\n",
            "Cost: 0.57734375, Train accuracy: 86.765625 %, Test accuracy: 88.0625 %\n",
            "Epoch number: 571 / 1000\n",
            "Cost: 0.549375, Train accuracy: 85.578125 %, Test accuracy: 85.9375 %\n",
            "Epoch number: 572 / 1000\n",
            "Cost: 0.5909375, Train accuracy: 85.5625 %, Test accuracy: 86.375 %\n",
            "Epoch number: 573 / 1000\n",
            "Cost: 0.55234375, Train accuracy: 78.875 %, Test accuracy: 78.0 %\n",
            "Epoch number: 574 / 1000\n",
            "Cost: 0.6515625, Train accuracy: 74.96875 %, Test accuracy: 76.5625 %\n",
            "Epoch number: 575 / 1000\n",
            "Cost: 0.62359375, Train accuracy: 77.359375 %, Test accuracy: 77.375 %\n",
            "Epoch number: 576 / 1000\n",
            "Cost: 0.621875, Train accuracy: 83.109375 %, Test accuracy: 84.375 %\n",
            "Epoch number: 577 / 1000\n",
            "Cost: 0.56171875, Train accuracy: 85.265625 %, Test accuracy: 86.0 %\n",
            "Epoch number: 578 / 1000\n",
            "Cost: 0.57703125, Train accuracy: 86.828125 %, Test accuracy: 88.0625 %\n",
            "Epoch number: 579 / 1000\n",
            "Cost: 0.54921875, Train accuracy: 85.640625 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 580 / 1000\n",
            "Cost: 0.5909375, Train accuracy: 85.59375 %, Test accuracy: 86.375 %\n",
            "Epoch number: 581 / 1000\n",
            "Cost: 0.55234375, Train accuracy: 78.78125 %, Test accuracy: 78.125 %\n",
            "Epoch number: 582 / 1000\n",
            "Cost: 0.65203125, Train accuracy: 74.828125 %, Test accuracy: 76.4375 %\n",
            "Epoch number: 583 / 1000\n",
            "Cost: 0.62421875, Train accuracy: 77.375 %, Test accuracy: 77.375 %\n",
            "Epoch number: 584 / 1000\n",
            "Cost: 0.62140625, Train accuracy: 83.1875 %, Test accuracy: 84.4375 %\n",
            "Epoch number: 585 / 1000\n",
            "Cost: 0.5615625, Train accuracy: 85.328125 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 586 / 1000\n",
            "Cost: 0.57671875, Train accuracy: 86.859375 %, Test accuracy: 88.0 %\n",
            "Epoch number: 587 / 1000\n",
            "Cost: 0.5490625, Train accuracy: 85.625 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 588 / 1000\n",
            "Cost: 0.5909375, Train accuracy: 85.578125 %, Test accuracy: 86.375 %\n",
            "Epoch number: 589 / 1000\n",
            "Cost: 0.5525, Train accuracy: 78.859375 %, Test accuracy: 78.0625 %\n",
            "Epoch number: 590 / 1000\n",
            "Cost: 0.6515625, Train accuracy: 74.859375 %, Test accuracy: 76.5 %\n",
            "Epoch number: 591 / 1000\n",
            "Cost: 0.62421875, Train accuracy: 77.375 %, Test accuracy: 77.375 %\n",
            "Epoch number: 592 / 1000\n",
            "Cost: 0.6215625, Train accuracy: 83.15625 %, Test accuracy: 84.4375 %\n",
            "Epoch number: 593 / 1000\n",
            "Cost: 0.56125, Train accuracy: 85.265625 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 594 / 1000\n",
            "Cost: 0.57703125, Train accuracy: 86.859375 %, Test accuracy: 88.0625 %\n",
            "Epoch number: 595 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 85.6875 %, Test accuracy: 86.1875 %\n",
            "Epoch number: 596 / 1000\n",
            "Cost: 0.59046875, Train accuracy: 85.546875 %, Test accuracy: 86.25 %\n",
            "Epoch number: 597 / 1000\n",
            "Cost: 0.553125, Train accuracy: 78.890625 %, Test accuracy: 78.1875 %\n",
            "Epoch number: 598 / 1000\n",
            "Cost: 0.65046875, Train accuracy: 74.9375 %, Test accuracy: 76.6875 %\n",
            "Epoch number: 599 / 1000\n",
            "Cost: 0.62375, Train accuracy: 77.234375 %, Test accuracy: 77.25 %\n",
            "Epoch number: 600 / 1000\n",
            "Cost: 0.6228125, Train accuracy: 83.03125 %, Test accuracy: 84.375 %\n",
            "Epoch number: 601 / 1000\n",
            "Cost: 0.56234375, Train accuracy: 85.265625 %, Test accuracy: 86.0 %\n",
            "Epoch number: 602 / 1000\n",
            "Cost: 0.57671875, Train accuracy: 86.859375 %, Test accuracy: 88.125 %\n",
            "Epoch number: 603 / 1000\n",
            "Cost: 0.549375, Train accuracy: 85.703125 %, Test accuracy: 86.125 %\n",
            "Epoch number: 604 / 1000\n",
            "Cost: 0.5903125, Train accuracy: 85.546875 %, Test accuracy: 86.4375 %\n",
            "Epoch number: 605 / 1000\n",
            "Cost: 0.5528125, Train accuracy: 78.890625 %, Test accuracy: 78.125 %\n",
            "Epoch number: 606 / 1000\n",
            "Cost: 0.6509375, Train accuracy: 74.90625 %, Test accuracy: 76.5 %\n",
            "Epoch number: 607 / 1000\n",
            "Cost: 0.62390625, Train accuracy: 77.328125 %, Test accuracy: 77.375 %\n",
            "Epoch number: 608 / 1000\n",
            "Cost: 0.62203125, Train accuracy: 83.15625 %, Test accuracy: 84.3125 %\n",
            "Epoch number: 609 / 1000\n",
            "Cost: 0.56140625, Train accuracy: 85.296875 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 610 / 1000\n",
            "Cost: 0.57671875, Train accuracy: 86.859375 %, Test accuracy: 88.0625 %\n",
            "Epoch number: 611 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 85.625 %, Test accuracy: 86.125 %\n",
            "Epoch number: 612 / 1000\n",
            "Cost: 0.5909375, Train accuracy: 85.515625 %, Test accuracy: 86.3125 %\n",
            "Epoch number: 613 / 1000\n",
            "Cost: 0.55328125, Train accuracy: 78.859375 %, Test accuracy: 78.1875 %\n",
            "Epoch number: 614 / 1000\n",
            "Cost: 0.650625, Train accuracy: 74.9375 %, Test accuracy: 76.6875 %\n",
            "Epoch number: 615 / 1000\n",
            "Cost: 0.62375, Train accuracy: 77.265625 %, Test accuracy: 77.25 %\n",
            "Epoch number: 616 / 1000\n",
            "Cost: 0.6225, Train accuracy: 83.046875 %, Test accuracy: 84.3125 %\n",
            "Epoch number: 617 / 1000\n",
            "Cost: 0.56234375, Train accuracy: 85.265625 %, Test accuracy: 86.0 %\n",
            "Epoch number: 618 / 1000\n",
            "Cost: 0.576875, Train accuracy: 86.796875 %, Test accuracy: 88.0625 %\n",
            "Epoch number: 619 / 1000\n",
            "Cost: 0.549375, Train accuracy: 85.609375 %, Test accuracy: 86.125 %\n",
            "Epoch number: 620 / 1000\n",
            "Cost: 0.5909375, Train accuracy: 85.578125 %, Test accuracy: 86.3125 %\n",
            "Epoch number: 621 / 1000\n",
            "Cost: 0.5525, Train accuracy: 78.984375 %, Test accuracy: 78.0625 %\n",
            "Epoch number: 622 / 1000\n",
            "Cost: 0.65046875, Train accuracy: 75.015625 %, Test accuracy: 76.6875 %\n",
            "Epoch number: 623 / 1000\n",
            "Cost: 0.62328125, Train accuracy: 77.296875 %, Test accuracy: 77.25 %\n",
            "Epoch number: 624 / 1000\n",
            "Cost: 0.6225, Train accuracy: 82.921875 %, Test accuracy: 84.25 %\n",
            "Epoch number: 625 / 1000\n",
            "Cost: 0.5628125, Train accuracy: 85.1875 %, Test accuracy: 85.75 %\n",
            "Epoch number: 626 / 1000\n",
            "Cost: 0.5778125, Train accuracy: 86.640625 %, Test accuracy: 88.0625 %\n",
            "Epoch number: 627 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 85.546875 %, Test accuracy: 85.9375 %\n",
            "Epoch number: 628 / 1000\n",
            "Cost: 0.59125, Train accuracy: 85.609375 %, Test accuracy: 86.4375 %\n",
            "Epoch number: 629 / 1000\n",
            "Cost: 0.55265625, Train accuracy: 78.921875 %, Test accuracy: 78.25 %\n",
            "Epoch number: 630 / 1000\n",
            "Cost: 0.65078125, Train accuracy: 75.15625 %, Test accuracy: 76.625 %\n",
            "Epoch number: 631 / 1000\n",
            "Cost: 0.6228125, Train accuracy: 77.375 %, Test accuracy: 77.375 %\n",
            "Epoch number: 632 / 1000\n",
            "Cost: 0.62140625, Train accuracy: 82.9375 %, Test accuracy: 84.125 %\n",
            "Epoch number: 633 / 1000\n",
            "Cost: 0.5628125, Train accuracy: 85.1875 %, Test accuracy: 85.75 %\n",
            "Epoch number: 634 / 1000\n",
            "Cost: 0.57859375, Train accuracy: 86.53125 %, Test accuracy: 87.9375 %\n",
            "Epoch number: 635 / 1000\n",
            "Cost: 0.55, Train accuracy: 85.328125 %, Test accuracy: 85.875 %\n",
            "Epoch number: 636 / 1000\n",
            "Cost: 0.5928125, Train accuracy: 85.40625 %, Test accuracy: 86.25 %\n",
            "Epoch number: 637 / 1000\n",
            "Cost: 0.55328125, Train accuracy: 78.9375 %, Test accuracy: 78.25 %\n",
            "Epoch number: 638 / 1000\n",
            "Cost: 0.64984375, Train accuracy: 75.390625 %, Test accuracy: 77.0 %\n",
            "Epoch number: 639 / 1000\n",
            "Cost: 0.62078125, Train accuracy: 77.578125 %, Test accuracy: 77.5 %\n",
            "Epoch number: 640 / 1000\n",
            "Cost: 0.620625, Train accuracy: 82.921875 %, Test accuracy: 84.25 %\n",
            "Epoch number: 641 / 1000\n",
            "Cost: 0.56359375, Train accuracy: 85.03125 %, Test accuracy: 85.6875 %\n",
            "Epoch number: 642 / 1000\n",
            "Cost: 0.58, Train accuracy: 86.53125 %, Test accuracy: 87.5625 %\n",
            "Epoch number: 643 / 1000\n",
            "Cost: 0.54984375, Train accuracy: 85.046875 %, Test accuracy: 85.5625 %\n",
            "Epoch number: 644 / 1000\n",
            "Cost: 0.5946875, Train accuracy: 85.078125 %, Test accuracy: 86.1875 %\n",
            "Epoch number: 645 / 1000\n",
            "Cost: 0.5559375, Train accuracy: 78.484375 %, Test accuracy: 77.9375 %\n",
            "Epoch number: 646 / 1000\n",
            "Cost: 0.6509375, Train accuracy: 75.484375 %, Test accuracy: 77.0625 %\n",
            "Epoch number: 647 / 1000\n",
            "Cost: 0.62015625, Train accuracy: 78.078125 %, Test accuracy: 78.125 %\n",
            "Epoch number: 648 / 1000\n",
            "Cost: 0.61609375, Train accuracy: 83.390625 %, Test accuracy: 84.6875 %\n",
            "Epoch number: 649 / 1000\n",
            "Cost: 0.560625, Train accuracy: 85.09375 %, Test accuracy: 85.625 %\n",
            "Epoch number: 650 / 1000\n",
            "Cost: 0.58125, Train accuracy: 86.46875 %, Test accuracy: 87.625 %\n",
            "Epoch number: 651 / 1000\n",
            "Cost: 0.55, Train accuracy: 84.78125 %, Test accuracy: 85.0625 %\n",
            "Epoch number: 652 / 1000\n",
            "Cost: 0.59859375, Train accuracy: 84.421875 %, Test accuracy: 85.4375 %\n",
            "Epoch number: 653 / 1000\n",
            "Cost: 0.56015625, Train accuracy: 78.0 %, Test accuracy: 77.1875 %\n",
            "Epoch number: 654 / 1000\n",
            "Cost: 0.65234375, Train accuracy: 75.703125 %, Test accuracy: 77.4375 %\n",
            "Epoch number: 655 / 1000\n",
            "Cost: 0.61734375, Train accuracy: 78.765625 %, Test accuracy: 78.875 %\n",
            "Epoch number: 656 / 1000\n",
            "Cost: 0.61015625, Train accuracy: 84.015625 %, Test accuracy: 85.1875 %\n",
            "Epoch number: 657 / 1000\n",
            "Cost: 0.55671875, Train accuracy: 84.96875 %, Test accuracy: 85.625 %\n",
            "Epoch number: 658 / 1000\n",
            "Cost: 0.58515625, Train accuracy: 86.265625 %, Test accuracy: 87.375 %\n",
            "Epoch number: 659 / 1000\n",
            "Cost: 0.5503125, Train accuracy: 84.125 %, Test accuracy: 84.1875 %\n",
            "Epoch number: 660 / 1000\n",
            "Cost: 0.60484375, Train accuracy: 83.59375 %, Test accuracy: 84.5625 %\n",
            "Epoch number: 661 / 1000\n",
            "Cost: 0.56625, Train accuracy: 77.40625 %, Test accuracy: 76.875 %\n",
            "Epoch number: 662 / 1000\n",
            "Cost: 0.6528125, Train accuracy: 76.0625 %, Test accuracy: 78.125 %\n",
            "Epoch number: 663 / 1000\n",
            "Cost: 0.61390625, Train accuracy: 79.8125 %, Test accuracy: 80.4375 %\n",
            "Epoch number: 664 / 1000\n",
            "Cost: 0.60375, Train accuracy: 84.5625 %, Test accuracy: 85.5 %\n",
            "Epoch number: 665 / 1000\n",
            "Cost: 0.55296875, Train accuracy: 84.875 %, Test accuracy: 85.625 %\n",
            "Epoch number: 666 / 1000\n",
            "Cost: 0.5884375, Train accuracy: 86.21875 %, Test accuracy: 87.0625 %\n",
            "Epoch number: 667 / 1000\n",
            "Cost: 0.5490625, Train accuracy: 83.65625 %, Test accuracy: 83.75 %\n",
            "Epoch number: 668 / 1000\n",
            "Cost: 0.60921875, Train accuracy: 82.546875 %, Test accuracy: 84.125 %\n",
            "Epoch number: 669 / 1000\n",
            "Cost: 0.57296875, Train accuracy: 76.828125 %, Test accuracy: 76.25 %\n",
            "Epoch number: 670 / 1000\n",
            "Cost: 0.654375, Train accuracy: 76.625 %, Test accuracy: 78.6875 %\n",
            "Epoch number: 671 / 1000\n",
            "Cost: 0.60890625, Train accuracy: 81.234375 %, Test accuracy: 81.0 %\n",
            "Epoch number: 672 / 1000\n",
            "Cost: 0.5940625, Train accuracy: 85.25 %, Test accuracy: 86.5 %\n",
            "Epoch number: 673 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 84.859375 %, Test accuracy: 85.5625 %\n",
            "Epoch number: 674 / 1000\n",
            "Cost: 0.5921875, Train accuracy: 86.03125 %, Test accuracy: 86.9375 %\n",
            "Epoch number: 675 / 1000\n",
            "Cost: 0.55046875, Train accuracy: 82.484375 %, Test accuracy: 82.75 %\n",
            "Epoch number: 676 / 1000\n",
            "Cost: 0.6190625, Train accuracy: 80.96875 %, Test accuracy: 82.125 %\n",
            "Epoch number: 677 / 1000\n",
            "Cost: 0.5815625, Train accuracy: 76.578125 %, Test accuracy: 76.3125 %\n",
            "Epoch number: 678 / 1000\n",
            "Cost: 0.6496875, Train accuracy: 78.34375 %, Test accuracy: 80.4375 %\n",
            "Epoch number: 679 / 1000\n",
            "Cost: 0.59578125, Train accuracy: 82.46875 %, Test accuracy: 82.625 %\n",
            "Epoch number: 680 / 1000\n",
            "Cost: 0.5884375, Train accuracy: 85.5 %, Test accuracy: 86.75 %\n",
            "Epoch number: 681 / 1000\n",
            "Cost: 0.54953125, Train accuracy: 84.453125 %, Test accuracy: 85.1875 %\n",
            "Epoch number: 682 / 1000\n",
            "Cost: 0.598125, Train accuracy: 85.234375 %, Test accuracy: 86.25 %\n",
            "Epoch number: 683 / 1000\n",
            "Cost: 0.55421875, Train accuracy: 80.84375 %, Test accuracy: 80.5625 %\n",
            "Epoch number: 684 / 1000\n",
            "Cost: 0.63125, Train accuracy: 79.3125 %, Test accuracy: 81.0 %\n",
            "Epoch number: 685 / 1000\n",
            "Cost: 0.59203125, Train accuracy: 77.5 %, Test accuracy: 77.6875 %\n",
            "Epoch number: 686 / 1000\n",
            "Cost: 0.6359375, Train accuracy: 80.625 %, Test accuracy: 82.0 %\n",
            "Epoch number: 687 / 1000\n",
            "Cost: 0.57890625, Train accuracy: 82.9375 %, Test accuracy: 83.125 %\n",
            "Epoch number: 688 / 1000\n",
            "Cost: 0.591875, Train accuracy: 85.484375 %, Test accuracy: 86.75 %\n",
            "Epoch number: 689 / 1000\n",
            "Cost: 0.55046875, Train accuracy: 83.796875 %, Test accuracy: 84.0 %\n",
            "Epoch number: 690 / 1000\n",
            "Cost: 0.60484375, Train accuracy: 84.25 %, Test accuracy: 85.125 %\n",
            "Epoch number: 691 / 1000\n",
            "Cost: 0.5615625, Train accuracy: 79.890625 %, Test accuracy: 79.75 %\n",
            "Epoch number: 692 / 1000\n",
            "Cost: 0.63359375, Train accuracy: 79.0625 %, Test accuracy: 80.875 %\n",
            "Epoch number: 693 / 1000\n",
            "Cost: 0.593125, Train accuracy: 78.703125 %, Test accuracy: 78.5625 %\n",
            "Epoch number: 694 / 1000\n",
            "Cost: 0.6246875, Train accuracy: 82.09375 %, Test accuracy: 83.4375 %\n",
            "Epoch number: 695 / 1000\n",
            "Cost: 0.570625, Train accuracy: 83.40625 %, Test accuracy: 83.4375 %\n",
            "Epoch number: 696 / 1000\n",
            "Cost: 0.59359375, Train accuracy: 85.375 %, Test accuracy: 86.4375 %\n",
            "Epoch number: 697 / 1000\n",
            "Cost: 0.5515625, Train accuracy: 83.09375 %, Test accuracy: 83.125 %\n",
            "Epoch number: 698 / 1000\n",
            "Cost: 0.61125, Train accuracy: 82.984375 %, Test accuracy: 84.1875 %\n",
            "Epoch number: 699 / 1000\n",
            "Cost: 0.56859375, Train accuracy: 79.078125 %, Test accuracy: 78.5625 %\n",
            "Epoch number: 700 / 1000\n",
            "Cost: 0.63640625, Train accuracy: 79.0625 %, Test accuracy: 81.0625 %\n",
            "Epoch number: 701 / 1000\n",
            "Cost: 0.59265625, Train accuracy: 80.03125 %, Test accuracy: 80.125 %\n",
            "Epoch number: 702 / 1000\n",
            "Cost: 0.61375, Train accuracy: 83.3125 %, Test accuracy: 84.5 %\n",
            "Epoch number: 703 / 1000\n",
            "Cost: 0.56265625, Train accuracy: 83.78125 %, Test accuracy: 84.0 %\n",
            "Epoch number: 704 / 1000\n",
            "Cost: 0.59359375, Train accuracy: 85.1875 %, Test accuracy: 86.1875 %\n",
            "Epoch number: 705 / 1000\n",
            "Cost: 0.5540625, Train accuracy: 82.0625 %, Test accuracy: 82.0 %\n",
            "Epoch number: 706 / 1000\n",
            "Cost: 0.62046875, Train accuracy: 81.203125 %, Test accuracy: 82.6875 %\n",
            "Epoch number: 707 / 1000\n",
            "Cost: 0.5796875, Train accuracy: 77.875 %, Test accuracy: 77.75 %\n",
            "Epoch number: 708 / 1000\n",
            "Cost: 0.64, Train accuracy: 79.484375 %, Test accuracy: 81.0625 %\n",
            "Epoch number: 709 / 1000\n",
            "Cost: 0.58921875, Train accuracy: 82.03125 %, Test accuracy: 82.1875 %\n",
            "Epoch number: 710 / 1000\n",
            "Cost: 0.5946875, Train accuracy: 85.203125 %, Test accuracy: 86.375 %\n",
            "Epoch number: 711 / 1000\n",
            "Cost: 0.551875, Train accuracy: 84.015625 %, Test accuracy: 84.3125 %\n",
            "Epoch number: 712 / 1000\n",
            "Cost: 0.60015625, Train accuracy: 84.640625 %, Test accuracy: 85.5625 %\n",
            "Epoch number: 713 / 1000\n",
            "Cost: 0.5590625, Train accuracy: 80.359375 %, Test accuracy: 79.9375 %\n",
            "Epoch number: 714 / 1000\n",
            "Cost: 0.6321875, Train accuracy: 79.03125 %, Test accuracy: 80.75 %\n",
            "Epoch number: 715 / 1000\n",
            "Cost: 0.59328125, Train accuracy: 78.09375 %, Test accuracy: 78.0 %\n",
            "Epoch number: 716 / 1000\n",
            "Cost: 0.6296875, Train accuracy: 81.46875 %, Test accuracy: 83.0 %\n",
            "Epoch number: 717 / 1000\n",
            "Cost: 0.57359375, Train accuracy: 83.234375 %, Test accuracy: 83.375 %\n",
            "Epoch number: 718 / 1000\n",
            "Cost: 0.59265625, Train accuracy: 85.421875 %, Test accuracy: 86.4375 %\n",
            "Epoch number: 719 / 1000\n",
            "Cost: 0.55140625, Train accuracy: 83.359375 %, Test accuracy: 83.5 %\n",
            "Epoch number: 720 / 1000\n",
            "Cost: 0.6084375, Train accuracy: 83.5625 %, Test accuracy: 84.625 %\n",
            "Epoch number: 721 / 1000\n",
            "Cost: 0.56609375, Train accuracy: 79.125 %, Test accuracy: 78.75 %\n",
            "Epoch number: 722 / 1000\n",
            "Cost: 0.63765625, Train accuracy: 78.96875 %, Test accuracy: 80.8125 %\n",
            "Epoch number: 723 / 1000\n",
            "Cost: 0.59265625, Train accuracy: 79.953125 %, Test accuracy: 79.8125 %\n",
            "Epoch number: 724 / 1000\n",
            "Cost: 0.61453125, Train accuracy: 83.09375 %, Test accuracy: 84.375 %\n",
            "Epoch number: 725 / 1000\n",
            "Cost: 0.5646875, Train accuracy: 83.609375 %, Test accuracy: 83.8125 %\n",
            "Epoch number: 726 / 1000\n",
            "Cost: 0.594375, Train accuracy: 85.171875 %, Test accuracy: 86.125 %\n",
            "Epoch number: 727 / 1000\n",
            "Cost: 0.55421875, Train accuracy: 82.234375 %, Test accuracy: 82.5 %\n",
            "Epoch number: 728 / 1000\n",
            "Cost: 0.61796875, Train accuracy: 81.484375 %, Test accuracy: 82.9375 %\n",
            "Epoch number: 729 / 1000\n",
            "Cost: 0.57796875, Train accuracy: 78.171875 %, Test accuracy: 78.0 %\n",
            "Epoch number: 730 / 1000\n",
            "Cost: 0.63890625, Train accuracy: 79.328125 %, Test accuracy: 81.0625 %\n",
            "Epoch number: 731 / 1000\n",
            "Cost: 0.590625, Train accuracy: 81.59375 %, Test accuracy: 81.375 %\n",
            "Epoch number: 732 / 1000\n",
            "Cost: 0.59921875, Train accuracy: 84.6875 %, Test accuracy: 85.9375 %\n",
            "Epoch number: 733 / 1000\n",
            "Cost: 0.55359375, Train accuracy: 83.984375 %, Test accuracy: 84.0 %\n",
            "Epoch number: 734 / 1000\n",
            "Cost: 0.59921875, Train accuracy: 84.765625 %, Test accuracy: 85.6875 %\n",
            "Epoch number: 735 / 1000\n",
            "Cost: 0.55828125, Train accuracy: 80.671875 %, Test accuracy: 80.1875 %\n",
            "Epoch number: 736 / 1000\n",
            "Cost: 0.63015625, Train accuracy: 79.65625 %, Test accuracy: 81.25 %\n",
            "Epoch number: 737 / 1000\n",
            "Cost: 0.58921875, Train accuracy: 78.234375 %, Test accuracy: 78.0 %\n",
            "Epoch number: 738 / 1000\n",
            "Cost: 0.62953125, Train accuracy: 81.1875 %, Test accuracy: 82.75 %\n",
            "Epoch number: 739 / 1000\n",
            "Cost: 0.57640625, Train accuracy: 82.84375 %, Test accuracy: 82.75 %\n",
            "Epoch number: 740 / 1000\n",
            "Cost: 0.5953125, Train accuracy: 85.21875 %, Test accuracy: 86.5 %\n",
            "Epoch number: 741 / 1000\n",
            "Cost: 0.55203125, Train accuracy: 83.640625 %, Test accuracy: 83.5625 %\n",
            "Epoch number: 742 / 1000\n",
            "Cost: 0.605625, Train accuracy: 83.96875 %, Test accuracy: 84.9375 %\n",
            "Epoch number: 743 / 1000\n",
            "Cost: 0.563125, Train accuracy: 79.546875 %, Test accuracy: 79.0625 %\n",
            "Epoch number: 744 / 1000\n",
            "Cost: 0.635625, Train accuracy: 78.921875 %, Test accuracy: 80.8125 %\n",
            "Epoch number: 745 / 1000\n",
            "Cost: 0.5934375, Train accuracy: 79.171875 %, Test accuracy: 79.1875 %\n",
            "Epoch number: 746 / 1000\n",
            "Cost: 0.62078125, Train accuracy: 82.515625 %, Test accuracy: 83.5625 %\n",
            "Epoch number: 747 / 1000\n",
            "Cost: 0.56734375, Train accuracy: 83.6875 %, Test accuracy: 83.875 %\n",
            "Epoch number: 748 / 1000\n",
            "Cost: 0.59265625, Train accuracy: 85.296875 %, Test accuracy: 86.1875 %\n",
            "Epoch number: 749 / 1000\n",
            "Cost: 0.55265625, Train accuracy: 82.609375 %, Test accuracy: 83.0625 %\n",
            "Epoch number: 750 / 1000\n",
            "Cost: 0.61609375, Train accuracy: 82.03125 %, Test accuracy: 83.625 %\n",
            "Epoch number: 751 / 1000\n",
            "Cost: 0.57453125, Train accuracy: 78.328125 %, Test accuracy: 78.25 %\n",
            "Epoch number: 752 / 1000\n",
            "Cost: 0.6396875, Train accuracy: 79.28125 %, Test accuracy: 81.125 %\n",
            "Epoch number: 753 / 1000\n",
            "Cost: 0.5909375, Train accuracy: 81.46875 %, Test accuracy: 81.3125 %\n",
            "Epoch number: 754 / 1000\n",
            "Cost: 0.6003125, Train accuracy: 84.625 %, Test accuracy: 85.8125 %\n",
            "Epoch number: 755 / 1000\n",
            "Cost: 0.554375, Train accuracy: 83.96875 %, Test accuracy: 83.9375 %\n",
            "Epoch number: 756 / 1000\n",
            "Cost: 0.59859375, Train accuracy: 84.828125 %, Test accuracy: 85.6875 %\n",
            "Epoch number: 757 / 1000\n",
            "Cost: 0.5575, Train accuracy: 80.609375 %, Test accuracy: 80.1875 %\n",
            "Epoch number: 758 / 1000\n",
            "Cost: 0.63015625, Train accuracy: 79.546875 %, Test accuracy: 81.1875 %\n",
            "Epoch number: 759 / 1000\n",
            "Cost: 0.59015625, Train accuracy: 77.984375 %, Test accuracy: 78.0 %\n",
            "Epoch number: 760 / 1000\n",
            "Cost: 0.63171875, Train accuracy: 80.90625 %, Test accuracy: 82.5625 %\n",
            "Epoch number: 761 / 1000\n",
            "Cost: 0.57765625, Train accuracy: 82.765625 %, Test accuracy: 82.75 %\n",
            "Epoch number: 762 / 1000\n",
            "Cost: 0.59546875, Train accuracy: 85.3125 %, Test accuracy: 86.5 %\n",
            "Epoch number: 763 / 1000\n",
            "Cost: 0.5515625, Train accuracy: 83.765625 %, Test accuracy: 83.625 %\n",
            "Epoch number: 764 / 1000\n",
            "Cost: 0.6040625, Train accuracy: 84.15625 %, Test accuracy: 85.1875 %\n",
            "Epoch number: 765 / 1000\n",
            "Cost: 0.56203125, Train accuracy: 79.71875 %, Test accuracy: 79.6875 %\n",
            "Epoch number: 766 / 1000\n",
            "Cost: 0.6346875, Train accuracy: 78.953125 %, Test accuracy: 80.8125 %\n",
            "Epoch number: 767 / 1000\n",
            "Cost: 0.59328125, Train accuracy: 79.125 %, Test accuracy: 79.0 %\n",
            "Epoch number: 768 / 1000\n",
            "Cost: 0.62203125, Train accuracy: 82.3125 %, Test accuracy: 83.5625 %\n",
            "Epoch number: 769 / 1000\n",
            "Cost: 0.56859375, Train accuracy: 83.59375 %, Test accuracy: 83.625 %\n",
            "Epoch number: 770 / 1000\n",
            "Cost: 0.5928125, Train accuracy: 85.296875 %, Test accuracy: 86.3125 %\n",
            "Epoch number: 771 / 1000\n",
            "Cost: 0.5525, Train accuracy: 82.796875 %, Test accuracy: 83.125 %\n",
            "Epoch number: 772 / 1000\n",
            "Cost: 0.61453125, Train accuracy: 82.578125 %, Test accuracy: 83.9375 %\n",
            "Epoch number: 773 / 1000\n",
            "Cost: 0.57140625, Train accuracy: 78.890625 %, Test accuracy: 78.6875 %\n",
            "Epoch number: 774 / 1000\n",
            "Cost: 0.63578125, Train accuracy: 79.40625 %, Test accuracy: 81.125 %\n",
            "Epoch number: 775 / 1000\n",
            "Cost: 0.58984375, Train accuracy: 80.53125 %, Test accuracy: 80.625 %\n",
            "Epoch number: 776 / 1000\n",
            "Cost: 0.61, Train accuracy: 83.609375 %, Test accuracy: 84.625 %\n",
            "Epoch number: 777 / 1000\n",
            "Cost: 0.56140625, Train accuracy: 83.515625 %, Test accuracy: 83.625 %\n",
            "Epoch number: 778 / 1000\n",
            "Cost: 0.5971875, Train accuracy: 84.859375 %, Test accuracy: 86.0 %\n",
            "Epoch number: 779 / 1000\n",
            "Cost: 0.55640625, Train accuracy: 81.5625 %, Test accuracy: 81.625 %\n",
            "Epoch number: 780 / 1000\n",
            "Cost: 0.62296875, Train accuracy: 80.75 %, Test accuracy: 82.0 %\n",
            "Epoch number: 781 / 1000\n",
            "Cost: 0.58203125, Train accuracy: 78.109375 %, Test accuracy: 77.8125 %\n",
            "Epoch number: 782 / 1000\n",
            "Cost: 0.63640625, Train accuracy: 80.171875 %, Test accuracy: 81.5 %\n",
            "Epoch number: 783 / 1000\n",
            "Cost: 0.58390625, Train accuracy: 82.203125 %, Test accuracy: 82.0625 %\n",
            "Epoch number: 784 / 1000\n",
            "Cost: 0.59578125, Train accuracy: 84.984375 %, Test accuracy: 86.3125 %\n",
            "Epoch number: 785 / 1000\n",
            "Cost: 0.55328125, Train accuracy: 83.671875 %, Test accuracy: 83.6875 %\n",
            "Epoch number: 786 / 1000\n",
            "Cost: 0.60421875, Train accuracy: 84.125 %, Test accuracy: 85.25 %\n",
            "Epoch number: 787 / 1000\n",
            "Cost: 0.56203125, Train accuracy: 79.90625 %, Test accuracy: 79.75 %\n",
            "Epoch number: 788 / 1000\n",
            "Cost: 0.63328125, Train accuracy: 79.25 %, Test accuracy: 81.0625 %\n",
            "Epoch number: 789 / 1000\n",
            "Cost: 0.59203125, Train accuracy: 78.90625 %, Test accuracy: 78.8125 %\n",
            "Epoch number: 790 / 1000\n",
            "Cost: 0.6234375, Train accuracy: 82.171875 %, Test accuracy: 83.5625 %\n",
            "Epoch number: 791 / 1000\n",
            "Cost: 0.5696875, Train accuracy: 83.4375 %, Test accuracy: 83.4375 %\n",
            "Epoch number: 792 / 1000\n",
            "Cost: 0.5940625, Train accuracy: 85.34375 %, Test accuracy: 86.4375 %\n",
            "Epoch number: 793 / 1000\n",
            "Cost: 0.551875, Train accuracy: 83.0 %, Test accuracy: 83.1875 %\n",
            "Epoch number: 794 / 1000\n",
            "Cost: 0.611875, Train accuracy: 82.859375 %, Test accuracy: 84.1875 %\n",
            "Epoch number: 795 / 1000\n",
            "Cost: 0.56984375, Train accuracy: 78.9375 %, Test accuracy: 78.5625 %\n",
            "Epoch number: 796 / 1000\n",
            "Cost: 0.63640625, Train accuracy: 79.125 %, Test accuracy: 81.1875 %\n",
            "Epoch number: 797 / 1000\n",
            "Cost: 0.591875, Train accuracy: 80.09375 %, Test accuracy: 80.25 %\n",
            "Epoch number: 798 / 1000\n",
            "Cost: 0.61359375, Train accuracy: 83.265625 %, Test accuracy: 84.5 %\n",
            "Epoch number: 799 / 1000\n",
            "Cost: 0.56296875, Train accuracy: 83.703125 %, Test accuracy: 84.0 %\n",
            "Epoch number: 800 / 1000\n",
            "Cost: 0.59421875, Train accuracy: 85.15625 %, Test accuracy: 86.25 %\n",
            "Epoch number: 801 / 1000\n",
            "Cost: 0.55421875, Train accuracy: 81.921875 %, Test accuracy: 82.0 %\n",
            "Epoch number: 802 / 1000\n",
            "Cost: 0.62140625, Train accuracy: 81.046875 %, Test accuracy: 82.4375 %\n",
            "Epoch number: 803 / 1000\n",
            "Cost: 0.58078125, Train accuracy: 77.953125 %, Test accuracy: 77.8125 %\n",
            "Epoch number: 804 / 1000\n",
            "Cost: 0.63875, Train accuracy: 79.828125 %, Test accuracy: 81.25 %\n",
            "Epoch number: 805 / 1000\n",
            "Cost: 0.58640625, Train accuracy: 82.1875 %, Test accuracy: 82.25 %\n",
            "Epoch number: 806 / 1000\n",
            "Cost: 0.59453125, Train accuracy: 85.125 %, Test accuracy: 86.3125 %\n",
            "Epoch number: 807 / 1000\n",
            "Cost: 0.55328125, Train accuracy: 83.859375 %, Test accuracy: 84.0 %\n",
            "Epoch number: 808 / 1000\n",
            "Cost: 0.6015625, Train accuracy: 84.546875 %, Test accuracy: 85.5625 %\n",
            "Epoch number: 809 / 1000\n",
            "Cost: 0.55953125, Train accuracy: 80.1875 %, Test accuracy: 79.9375 %\n",
            "Epoch number: 810 / 1000\n",
            "Cost: 0.63203125, Train accuracy: 79.03125 %, Test accuracy: 80.875 %\n",
            "Epoch number: 811 / 1000\n",
            "Cost: 0.5934375, Train accuracy: 78.28125 %, Test accuracy: 78.25 %\n",
            "Epoch number: 812 / 1000\n",
            "Cost: 0.628125, Train accuracy: 81.6875 %, Test accuracy: 83.0625 %\n",
            "Epoch number: 813 / 1000\n",
            "Cost: 0.57265625, Train accuracy: 83.265625 %, Test accuracy: 83.3125 %\n",
            "Epoch number: 814 / 1000\n",
            "Cost: 0.59328125, Train accuracy: 85.421875 %, Test accuracy: 86.4375 %\n",
            "Epoch number: 815 / 1000\n",
            "Cost: 0.55140625, Train accuracy: 83.375 %, Test accuracy: 83.5 %\n",
            "Epoch number: 816 / 1000\n",
            "Cost: 0.608125, Train accuracy: 83.578125 %, Test accuracy: 84.625 %\n",
            "Epoch number: 817 / 1000\n",
            "Cost: 0.56578125, Train accuracy: 79.015625 %, Test accuracy: 78.6875 %\n",
            "Epoch number: 818 / 1000\n",
            "Cost: 0.6384375, Train accuracy: 78.75 %, Test accuracy: 80.6875 %\n",
            "Epoch number: 819 / 1000\n",
            "Cost: 0.59375, Train accuracy: 79.96875 %, Test accuracy: 79.8125 %\n",
            "Epoch number: 820 / 1000\n",
            "Cost: 0.61421875, Train accuracy: 83.328125 %, Test accuracy: 84.375 %\n",
            "Epoch number: 821 / 1000\n",
            "Cost: 0.56296875, Train accuracy: 83.84375 %, Test accuracy: 84.1875 %\n",
            "Epoch number: 822 / 1000\n",
            "Cost: 0.59265625, Train accuracy: 85.21875 %, Test accuracy: 86.25 %\n",
            "Epoch number: 823 / 1000\n",
            "Cost: 0.55390625, Train accuracy: 81.9375 %, Test accuracy: 82.0625 %\n",
            "Epoch number: 824 / 1000\n",
            "Cost: 0.6215625, Train accuracy: 81.03125 %, Test accuracy: 82.4375 %\n",
            "Epoch number: 825 / 1000\n",
            "Cost: 0.58109375, Train accuracy: 77.96875 %, Test accuracy: 77.8125 %\n",
            "Epoch number: 826 / 1000\n",
            "Cost: 0.6390625, Train accuracy: 79.796875 %, Test accuracy: 81.25 %\n",
            "Epoch number: 827 / 1000\n",
            "Cost: 0.5865625, Train accuracy: 82.265625 %, Test accuracy: 82.3125 %\n",
            "Epoch number: 828 / 1000\n",
            "Cost: 0.59359375, Train accuracy: 85.265625 %, Test accuracy: 86.625 %\n",
            "Epoch number: 829 / 1000\n",
            "Cost: 0.5515625, Train accuracy: 83.890625 %, Test accuracy: 84.125 %\n",
            "Epoch number: 830 / 1000\n",
            "Cost: 0.601875, Train accuracy: 84.46875 %, Test accuracy: 85.4375 %\n",
            "Epoch number: 831 / 1000\n",
            "Cost: 0.560625, Train accuracy: 80.109375 %, Test accuracy: 79.9375 %\n",
            "Epoch number: 832 / 1000\n",
            "Cost: 0.6328125, Train accuracy: 78.984375 %, Test accuracy: 80.75 %\n",
            "Epoch number: 833 / 1000\n",
            "Cost: 0.59328125, Train accuracy: 78.265625 %, Test accuracy: 78.3125 %\n",
            "Epoch number: 834 / 1000\n",
            "Cost: 0.62859375, Train accuracy: 81.65625 %, Test accuracy: 83.0625 %\n",
            "Epoch number: 835 / 1000\n",
            "Cost: 0.57265625, Train accuracy: 83.28125 %, Test accuracy: 83.4375 %\n",
            "Epoch number: 836 / 1000\n",
            "Cost: 0.5928125, Train accuracy: 85.421875 %, Test accuracy: 86.4375 %\n",
            "Epoch number: 837 / 1000\n",
            "Cost: 0.55140625, Train accuracy: 83.390625 %, Test accuracy: 83.5 %\n",
            "Epoch number: 838 / 1000\n",
            "Cost: 0.60796875, Train accuracy: 83.578125 %, Test accuracy: 84.625 %\n",
            "Epoch number: 839 / 1000\n",
            "Cost: 0.56609375, Train accuracy: 78.921875 %, Test accuracy: 78.625 %\n",
            "Epoch number: 840 / 1000\n",
            "Cost: 0.63921875, Train accuracy: 78.703125 %, Test accuracy: 80.5625 %\n",
            "Epoch number: 841 / 1000\n",
            "Cost: 0.59421875, Train accuracy: 80.03125 %, Test accuracy: 80.0 %\n",
            "Epoch number: 842 / 1000\n",
            "Cost: 0.6134375, Train accuracy: 83.390625 %, Test accuracy: 84.5625 %\n",
            "Epoch number: 843 / 1000\n",
            "Cost: 0.56234375, Train accuracy: 83.84375 %, Test accuracy: 84.1875 %\n",
            "Epoch number: 844 / 1000\n",
            "Cost: 0.593125, Train accuracy: 85.265625 %, Test accuracy: 86.25 %\n",
            "Epoch number: 845 / 1000\n",
            "Cost: 0.5534375, Train accuracy: 82.09375 %, Test accuracy: 82.125 %\n",
            "Epoch number: 846 / 1000\n",
            "Cost: 0.62046875, Train accuracy: 81.21875 %, Test accuracy: 82.75 %\n",
            "Epoch number: 847 / 1000\n",
            "Cost: 0.5796875, Train accuracy: 77.84375 %, Test accuracy: 77.75 %\n",
            "Epoch number: 848 / 1000\n",
            "Cost: 0.640625, Train accuracy: 79.4375 %, Test accuracy: 81.0625 %\n",
            "Epoch number: 849 / 1000\n",
            "Cost: 0.58953125, Train accuracy: 82.03125 %, Test accuracy: 82.0625 %\n",
            "Epoch number: 850 / 1000\n",
            "Cost: 0.59453125, Train accuracy: 85.25 %, Test accuracy: 86.5625 %\n",
            "Epoch number: 851 / 1000\n",
            "Cost: 0.55140625, Train accuracy: 84.03125 %, Test accuracy: 84.3125 %\n",
            "Epoch number: 852 / 1000\n",
            "Cost: 0.60015625, Train accuracy: 84.6875 %, Test accuracy: 85.5625 %\n",
            "Epoch number: 853 / 1000\n",
            "Cost: 0.55890625, Train accuracy: 80.375 %, Test accuracy: 79.9375 %\n",
            "Epoch number: 854 / 1000\n",
            "Cost: 0.63203125, Train accuracy: 79.046875 %, Test accuracy: 80.8125 %\n",
            "Epoch number: 855 / 1000\n",
            "Cost: 0.593125, Train accuracy: 78.109375 %, Test accuracy: 78.0625 %\n",
            "Epoch number: 856 / 1000\n",
            "Cost: 0.6296875, Train accuracy: 81.484375 %, Test accuracy: 83.0 %\n",
            "Epoch number: 857 / 1000\n",
            "Cost: 0.57359375, Train accuracy: 83.234375 %, Test accuracy: 83.375 %\n",
            "Epoch number: 858 / 1000\n",
            "Cost: 0.59265625, Train accuracy: 85.4375 %, Test accuracy: 86.4375 %\n",
            "Epoch number: 859 / 1000\n",
            "Cost: 0.55125, Train accuracy: 83.359375 %, Test accuracy: 83.5 %\n",
            "Epoch number: 860 / 1000\n",
            "Cost: 0.60828125, Train accuracy: 83.578125 %, Test accuracy: 84.625 %\n",
            "Epoch number: 861 / 1000\n",
            "Cost: 0.56609375, Train accuracy: 79.015625 %, Test accuracy: 78.6875 %\n",
            "Epoch number: 862 / 1000\n",
            "Cost: 0.63859375, Train accuracy: 78.875 %, Test accuracy: 80.75 %\n",
            "Epoch number: 863 / 1000\n",
            "Cost: 0.5928125, Train accuracy: 80.09375 %, Test accuracy: 80.0625 %\n",
            "Epoch number: 864 / 1000\n",
            "Cost: 0.61359375, Train accuracy: 83.34375 %, Test accuracy: 84.4375 %\n",
            "Epoch number: 865 / 1000\n",
            "Cost: 0.56265625, Train accuracy: 83.75 %, Test accuracy: 84.0 %\n",
            "Epoch number: 866 / 1000\n",
            "Cost: 0.5940625, Train accuracy: 85.15625 %, Test accuracy: 86.1875 %\n",
            "Epoch number: 867 / 1000\n",
            "Cost: 0.5540625, Train accuracy: 81.90625 %, Test accuracy: 82.0 %\n",
            "Epoch number: 868 / 1000\n",
            "Cost: 0.6215625, Train accuracy: 81.0625 %, Test accuracy: 82.5625 %\n",
            "Epoch number: 869 / 1000\n",
            "Cost: 0.58078125, Train accuracy: 78.0625 %, Test accuracy: 77.75 %\n",
            "Epoch number: 870 / 1000\n",
            "Cost: 0.638125, Train accuracy: 79.984375 %, Test accuracy: 81.25 %\n",
            "Epoch number: 871 / 1000\n",
            "Cost: 0.585, Train accuracy: 82.28125 %, Test accuracy: 82.3125 %\n",
            "Epoch number: 872 / 1000\n",
            "Cost: 0.59421875, Train accuracy: 85.234375 %, Test accuracy: 86.4375 %\n",
            "Epoch number: 873 / 1000\n",
            "Cost: 0.55203125, Train accuracy: 83.828125 %, Test accuracy: 83.8125 %\n",
            "Epoch number: 874 / 1000\n",
            "Cost: 0.6028125, Train accuracy: 84.328125 %, Test accuracy: 85.3125 %\n",
            "Epoch number: 875 / 1000\n",
            "Cost: 0.56140625, Train accuracy: 79.90625 %, Test accuracy: 79.8125 %\n",
            "Epoch number: 876 / 1000\n",
            "Cost: 0.63375, Train accuracy: 78.921875 %, Test accuracy: 80.6875 %\n",
            "Epoch number: 877 / 1000\n",
            "Cost: 0.59328125, Train accuracy: 78.546875 %, Test accuracy: 78.4375 %\n",
            "Epoch number: 878 / 1000\n",
            "Cost: 0.62625, Train accuracy: 81.953125 %, Test accuracy: 83.3125 %\n",
            "Epoch number: 879 / 1000\n",
            "Cost: 0.57171875, Train accuracy: 83.328125 %, Test accuracy: 83.4375 %\n",
            "Epoch number: 880 / 1000\n",
            "Cost: 0.5928125, Train accuracy: 85.453125 %, Test accuracy: 86.4375 %\n",
            "Epoch number: 881 / 1000\n",
            "Cost: 0.55140625, Train accuracy: 83.171875 %, Test accuracy: 83.125 %\n",
            "Epoch number: 882 / 1000\n",
            "Cost: 0.6103125, Train accuracy: 83.078125 %, Test accuracy: 84.3125 %\n",
            "Epoch number: 883 / 1000\n",
            "Cost: 0.56859375, Train accuracy: 78.953125 %, Test accuracy: 78.5 %\n",
            "Epoch number: 884 / 1000\n",
            "Cost: 0.6375, Train accuracy: 79.0625 %, Test accuracy: 80.9375 %\n",
            "Epoch number: 885 / 1000\n",
            "Cost: 0.59234375, Train accuracy: 80.109375 %, Test accuracy: 80.25 %\n",
            "Epoch number: 886 / 1000\n",
            "Cost: 0.613125, Train accuracy: 83.328125 %, Test accuracy: 84.625 %\n",
            "Epoch number: 887 / 1000\n",
            "Cost: 0.5625, Train accuracy: 83.765625 %, Test accuracy: 84.0 %\n",
            "Epoch number: 888 / 1000\n",
            "Cost: 0.59390625, Train accuracy: 85.15625 %, Test accuracy: 86.25 %\n",
            "Epoch number: 889 / 1000\n",
            "Cost: 0.55421875, Train accuracy: 81.953125 %, Test accuracy: 81.9375 %\n",
            "Epoch number: 890 / 1000\n",
            "Cost: 0.6209375, Train accuracy: 81.09375 %, Test accuracy: 82.625 %\n",
            "Epoch number: 891 / 1000\n",
            "Cost: 0.58046875, Train accuracy: 78.015625 %, Test accuracy: 77.875 %\n",
            "Epoch number: 892 / 1000\n",
            "Cost: 0.63890625, Train accuracy: 79.796875 %, Test accuracy: 81.25 %\n",
            "Epoch number: 893 / 1000\n",
            "Cost: 0.586875, Train accuracy: 82.1875 %, Test accuracy: 82.25 %\n",
            "Epoch number: 894 / 1000\n",
            "Cost: 0.59421875, Train accuracy: 85.25 %, Test accuracy: 86.375 %\n",
            "Epoch number: 895 / 1000\n",
            "Cost: 0.551875, Train accuracy: 83.890625 %, Test accuracy: 84.25 %\n",
            "Epoch number: 896 / 1000\n",
            "Cost: 0.60125, Train accuracy: 84.515625 %, Test accuracy: 85.5 %\n",
            "Epoch number: 897 / 1000\n",
            "Cost: 0.5603125, Train accuracy: 80.140625 %, Test accuracy: 79.875 %\n",
            "Epoch number: 898 / 1000\n",
            "Cost: 0.6328125, Train accuracy: 78.984375 %, Test accuracy: 80.6875 %\n",
            "Epoch number: 899 / 1000\n",
            "Cost: 0.59328125, Train accuracy: 78.265625 %, Test accuracy: 78.3125 %\n",
            "Epoch number: 900 / 1000\n",
            "Cost: 0.6284375, Train accuracy: 81.703125 %, Test accuracy: 83.0625 %\n",
            "Epoch number: 901 / 1000\n",
            "Cost: 0.5728125, Train accuracy: 83.296875 %, Test accuracy: 83.375 %\n",
            "Epoch number: 902 / 1000\n",
            "Cost: 0.5928125, Train accuracy: 85.4375 %, Test accuracy: 86.5 %\n",
            "Epoch number: 903 / 1000\n",
            "Cost: 0.55125, Train accuracy: 83.359375 %, Test accuracy: 83.4375 %\n",
            "Epoch number: 904 / 1000\n",
            "Cost: 0.60828125, Train accuracy: 83.515625 %, Test accuracy: 84.5625 %\n",
            "Epoch number: 905 / 1000\n",
            "Cost: 0.56609375, Train accuracy: 79.078125 %, Test accuracy: 78.6875 %\n",
            "Epoch number: 906 / 1000\n",
            "Cost: 0.6378125, Train accuracy: 78.9375 %, Test accuracy: 80.8125 %\n",
            "Epoch number: 907 / 1000\n",
            "Cost: 0.593125, Train accuracy: 79.921875 %, Test accuracy: 79.9375 %\n",
            "Epoch number: 908 / 1000\n",
            "Cost: 0.61484375, Train accuracy: 83.140625 %, Test accuracy: 84.4375 %\n",
            "Epoch number: 909 / 1000\n",
            "Cost: 0.56421875, Train accuracy: 83.71875 %, Test accuracy: 83.8125 %\n",
            "Epoch number: 910 / 1000\n",
            "Cost: 0.59375, Train accuracy: 85.21875 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 911 / 1000\n",
            "Cost: 0.55375, Train accuracy: 82.203125 %, Test accuracy: 82.4375 %\n",
            "Epoch number: 912 / 1000\n",
            "Cost: 0.61859375, Train accuracy: 81.4375 %, Test accuracy: 82.875 %\n",
            "Epoch number: 913 / 1000\n",
            "Cost: 0.578125, Train accuracy: 78.09375 %, Test accuracy: 77.9375 %\n",
            "Epoch number: 914 / 1000\n",
            "Cost: 0.6396875, Train accuracy: 79.328125 %, Test accuracy: 81.0625 %\n",
            "Epoch number: 915 / 1000\n",
            "Cost: 0.59015625, Train accuracy: 81.796875 %, Test accuracy: 81.6875 %\n",
            "Epoch number: 916 / 1000\n",
            "Cost: 0.59734375, Train accuracy: 84.875 %, Test accuracy: 85.75 %\n",
            "Epoch number: 917 / 1000\n",
            "Cost: 0.5534375, Train accuracy: 83.984375 %, Test accuracy: 84.125 %\n",
            "Epoch number: 918 / 1000\n",
            "Cost: 0.59953125, Train accuracy: 84.6875 %, Test accuracy: 85.625 %\n",
            "Epoch number: 919 / 1000\n",
            "Cost: 0.5584375, Train accuracy: 80.546875 %, Test accuracy: 80.1875 %\n",
            "Epoch number: 920 / 1000\n",
            "Cost: 0.6303125, Train accuracy: 79.546875 %, Test accuracy: 81.125 %\n",
            "Epoch number: 921 / 1000\n",
            "Cost: 0.59, Train accuracy: 78.171875 %, Test accuracy: 78.0 %\n",
            "Epoch number: 922 / 1000\n",
            "Cost: 0.630625, Train accuracy: 81.078125 %, Test accuracy: 82.8125 %\n",
            "Epoch number: 923 / 1000\n",
            "Cost: 0.5765625, Train accuracy: 82.890625 %, Test accuracy: 82.8125 %\n",
            "Epoch number: 924 / 1000\n",
            "Cost: 0.5946875, Train accuracy: 85.25 %, Test accuracy: 86.5 %\n",
            "Epoch number: 925 / 1000\n",
            "Cost: 0.55203125, Train accuracy: 83.671875 %, Test accuracy: 83.6875 %\n",
            "Epoch number: 926 / 1000\n",
            "Cost: 0.60515625, Train accuracy: 84.0 %, Test accuracy: 84.9375 %\n",
            "Epoch number: 927 / 1000\n",
            "Cost: 0.563125, Train accuracy: 79.40625 %, Test accuracy: 79.0 %\n",
            "Epoch number: 928 / 1000\n",
            "Cost: 0.6371875, Train accuracy: 78.8125 %, Test accuracy: 80.625 %\n",
            "Epoch number: 929 / 1000\n",
            "Cost: 0.59390625, Train accuracy: 79.453125 %, Test accuracy: 79.375 %\n",
            "Epoch number: 930 / 1000\n",
            "Cost: 0.6178125, Train accuracy: 82.859375 %, Test accuracy: 84.125 %\n",
            "Epoch number: 931 / 1000\n",
            "Cost: 0.56625, Train accuracy: 83.734375 %, Test accuracy: 83.8125 %\n",
            "Epoch number: 932 / 1000\n",
            "Cost: 0.59296875, Train accuracy: 85.28125 %, Test accuracy: 86.25 %\n",
            "Epoch number: 933 / 1000\n",
            "Cost: 0.55296875, Train accuracy: 82.328125 %, Test accuracy: 82.5625 %\n",
            "Epoch number: 934 / 1000\n",
            "Cost: 0.61796875, Train accuracy: 81.625 %, Test accuracy: 83.1875 %\n",
            "Epoch number: 935 / 1000\n",
            "Cost: 0.576875, Train accuracy: 78.34375 %, Test accuracy: 78.125 %\n",
            "Epoch number: 936 / 1000\n",
            "Cost: 0.6378125, Train accuracy: 79.4375 %, Test accuracy: 81.1875 %\n",
            "Epoch number: 937 / 1000\n",
            "Cost: 0.58984375, Train accuracy: 81.46875 %, Test accuracy: 81.25 %\n",
            "Epoch number: 938 / 1000\n",
            "Cost: 0.6009375, Train accuracy: 84.625 %, Test accuracy: 85.75 %\n",
            "Epoch number: 939 / 1000\n",
            "Cost: 0.55421875, Train accuracy: 84.0 %, Test accuracy: 84.0 %\n",
            "Epoch number: 940 / 1000\n",
            "Cost: 0.59859375, Train accuracy: 84.8125 %, Test accuracy: 85.75 %\n",
            "Epoch number: 941 / 1000\n",
            "Cost: 0.55765625, Train accuracy: 80.71875 %, Test accuracy: 80.25 %\n",
            "Epoch number: 942 / 1000\n",
            "Cost: 0.63, Train accuracy: 79.6875 %, Test accuracy: 81.3125 %\n",
            "Epoch number: 943 / 1000\n",
            "Cost: 0.58890625, Train accuracy: 78.046875 %, Test accuracy: 78.0625 %\n",
            "Epoch number: 944 / 1000\n",
            "Cost: 0.63171875, Train accuracy: 80.90625 %, Test accuracy: 82.5 %\n",
            "Epoch number: 945 / 1000\n",
            "Cost: 0.5778125, Train accuracy: 82.671875 %, Test accuracy: 82.6875 %\n",
            "Epoch number: 946 / 1000\n",
            "Cost: 0.5953125, Train accuracy: 85.296875 %, Test accuracy: 86.5 %\n",
            "Epoch number: 947 / 1000\n",
            "Cost: 0.551875, Train accuracy: 83.765625 %, Test accuracy: 83.75 %\n",
            "Epoch number: 948 / 1000\n",
            "Cost: 0.604375, Train accuracy: 84.1875 %, Test accuracy: 85.1875 %\n",
            "Epoch number: 949 / 1000\n",
            "Cost: 0.561875, Train accuracy: 79.765625 %, Test accuracy: 79.8125 %\n",
            "Epoch number: 950 / 1000\n",
            "Cost: 0.634375, Train accuracy: 79.015625 %, Test accuracy: 80.8125 %\n",
            "Epoch number: 951 / 1000\n",
            "Cost: 0.59296875, Train accuracy: 78.921875 %, Test accuracy: 78.8125 %\n",
            "Epoch number: 952 / 1000\n",
            "Cost: 0.62359375, Train accuracy: 82.234375 %, Test accuracy: 83.5 %\n",
            "Epoch number: 953 / 1000\n",
            "Cost: 0.56921875, Train accuracy: 83.5625 %, Test accuracy: 83.625 %\n",
            "Epoch number: 954 / 1000\n",
            "Cost: 0.59265625, Train accuracy: 85.359375 %, Test accuracy: 86.4375 %\n",
            "Epoch number: 955 / 1000\n",
            "Cost: 0.55203125, Train accuracy: 82.90625 %, Test accuracy: 83.1875 %\n",
            "Epoch number: 956 / 1000\n",
            "Cost: 0.61296875, Train accuracy: 82.75 %, Test accuracy: 84.125 %\n",
            "Epoch number: 957 / 1000\n",
            "Cost: 0.570625, Train accuracy: 78.75 %, Test accuracy: 78.625 %\n",
            "Epoch number: 958 / 1000\n",
            "Cost: 0.63703125, Train accuracy: 79.28125 %, Test accuracy: 81.125 %\n",
            "Epoch number: 959 / 1000\n",
            "Cost: 0.59125, Train accuracy: 80.46875 %, Test accuracy: 80.5625 %\n",
            "Epoch number: 960 / 1000\n",
            "Cost: 0.60953125, Train accuracy: 83.640625 %, Test accuracy: 84.5625 %\n",
            "Epoch number: 961 / 1000\n",
            "Cost: 0.56140625, Train accuracy: 83.515625 %, Test accuracy: 83.6875 %\n",
            "Epoch number: 962 / 1000\n",
            "Cost: 0.59703125, Train accuracy: 84.890625 %, Test accuracy: 86.0625 %\n",
            "Epoch number: 963 / 1000\n",
            "Cost: 0.55625, Train accuracy: 81.625 %, Test accuracy: 81.75 %\n",
            "Epoch number: 964 / 1000\n",
            "Cost: 0.62265625, Train accuracy: 80.859375 %, Test accuracy: 82.3125 %\n",
            "Epoch number: 965 / 1000\n",
            "Cost: 0.58171875, Train accuracy: 78.21875 %, Test accuracy: 77.75 %\n",
            "Epoch number: 966 / 1000\n",
            "Cost: 0.63546875, Train accuracy: 80.140625 %, Test accuracy: 81.5 %\n",
            "Epoch number: 967 / 1000\n",
            "Cost: 0.58375, Train accuracy: 82.109375 %, Test accuracy: 82.0625 %\n",
            "Epoch number: 968 / 1000\n",
            "Cost: 0.5975, Train accuracy: 84.859375 %, Test accuracy: 85.9375 %\n",
            "Epoch number: 969 / 1000\n",
            "Cost: 0.55421875, Train accuracy: 83.65625 %, Test accuracy: 83.5 %\n",
            "Epoch number: 970 / 1000\n",
            "Cost: 0.60328125, Train accuracy: 84.21875 %, Test accuracy: 85.25 %\n",
            "Epoch number: 971 / 1000\n",
            "Cost: 0.56125, Train accuracy: 80.1875 %, Test accuracy: 80.125 %\n",
            "Epoch number: 972 / 1000\n",
            "Cost: 0.63140625, Train accuracy: 79.390625 %, Test accuracy: 81.1875 %\n",
            "Epoch number: 973 / 1000\n",
            "Cost: 0.59109375, Train accuracy: 78.75 %, Test accuracy: 78.5625 %\n",
            "Epoch number: 974 / 1000\n",
            "Cost: 0.625625, Train accuracy: 81.875 %, Test accuracy: 83.3125 %\n",
            "Epoch number: 975 / 1000\n",
            "Cost: 0.57203125, Train accuracy: 83.078125 %, Test accuracy: 83.1875 %\n",
            "Epoch number: 976 / 1000\n",
            "Cost: 0.59484375, Train accuracy: 85.25 %, Test accuracy: 86.375 %\n",
            "Epoch number: 977 / 1000\n",
            "Cost: 0.5521875, Train accuracy: 83.25 %, Test accuracy: 83.5 %\n",
            "Epoch number: 978 / 1000\n",
            "Cost: 0.609375, Train accuracy: 83.375 %, Test accuracy: 84.5 %\n",
            "Epoch number: 979 / 1000\n",
            "Cost: 0.5665625, Train accuracy: 78.953125 %, Test accuracy: 78.625 %\n",
            "Epoch number: 980 / 1000\n",
            "Cost: 0.63859375, Train accuracy: 78.90625 %, Test accuracy: 80.75 %\n",
            "Epoch number: 981 / 1000\n",
            "Cost: 0.59296875, Train accuracy: 80.0625 %, Test accuracy: 80.0625 %\n",
            "Epoch number: 982 / 1000\n",
            "Cost: 0.6134375, Train accuracy: 83.296875 %, Test accuracy: 84.5 %\n",
            "Epoch number: 983 / 1000\n",
            "Cost: 0.5628125, Train accuracy: 83.71875 %, Test accuracy: 84.0 %\n",
            "Epoch number: 984 / 1000\n",
            "Cost: 0.59421875, Train accuracy: 85.15625 %, Test accuracy: 86.1875 %\n",
            "Epoch number: 985 / 1000\n",
            "Cost: 0.5540625, Train accuracy: 82.015625 %, Test accuracy: 82.0625 %\n",
            "Epoch number: 986 / 1000\n",
            "Cost: 0.6203125, Train accuracy: 81.1875 %, Test accuracy: 82.75 %\n",
            "Epoch number: 987 / 1000\n",
            "Cost: 0.57984375, Train accuracy: 77.90625 %, Test accuracy: 77.875 %\n",
            "Epoch number: 988 / 1000\n",
            "Cost: 0.64, Train accuracy: 79.5625 %, Test accuracy: 81.0625 %\n",
            "Epoch number: 989 / 1000\n",
            "Cost: 0.58859375, Train accuracy: 82.15625 %, Test accuracy: 82.1875 %\n",
            "Epoch number: 990 / 1000\n",
            "Cost: 0.59390625, Train accuracy: 85.234375 %, Test accuracy: 86.5 %\n",
            "Epoch number: 991 / 1000\n",
            "Cost: 0.551875, Train accuracy: 83.984375 %, Test accuracy: 84.25 %\n",
            "Epoch number: 992 / 1000\n",
            "Cost: 0.600625, Train accuracy: 84.65625 %, Test accuracy: 85.5625 %\n",
            "Epoch number: 993 / 1000\n",
            "Cost: 0.55890625, Train accuracy: 80.25 %, Test accuracy: 79.8125 %\n",
            "Epoch number: 994 / 1000\n",
            "Cost: 0.633125, Train accuracy: 79.015625 %, Test accuracy: 80.6875 %\n",
            "Epoch number: 995 / 1000\n",
            "Cost: 0.5934375, Train accuracy: 78.296875 %, Test accuracy: 78.25 %\n",
            "Epoch number: 996 / 1000\n",
            "Cost: 0.62765625, Train accuracy: 81.71875 %, Test accuracy: 83.125 %\n",
            "Epoch number: 997 / 1000\n",
            "Cost: 0.5725, Train accuracy: 83.3125 %, Test accuracy: 83.4375 %\n",
            "Epoch number: 998 / 1000\n",
            "Cost: 0.59296875, Train accuracy: 85.390625 %, Test accuracy: 86.4375 %\n",
            "Epoch number: 999 / 1000\n",
            "Cost: 0.5515625, Train accuracy: 83.34375 %, Test accuracy: 83.4375 %\n",
            "Training completed!\n",
            "[[636 145]\n",
            " [101 718]]\n",
            "Train accuracy: 83.546875 %, Test accuracy: 84.625 %\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "+\n",
        "train_values = model_0['train_history']\n",
        "test_values = model_0['test_history']\n",
        "plt.plot(list(range(len(train_values))),train_values)\n",
        "plt.plot(list(range(len(test_values))), test_values)\n",
        "plt.title('Evolution of the accuracy by iteration')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['train accuracy', 'test accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "g-Rk067ml_dj",
        "outputId": "da3df0f6-a763-48fb-93b9-9b29ec8d2d4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7d69e8f92590>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(2):\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYO0kbyQpqyB",
        "outputId": "1b28f3aa-6796-4576-b96c-3655e3797cb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "++"
      ],
      "metadata": {
        "id": "pjFdGKLRxAum"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
